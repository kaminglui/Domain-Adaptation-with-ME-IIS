# ME-IIS Repo Audit (Factual)

This document is a file-level and code-path audit of the repository in the current workspace. All claims below are traceable to code, notebook contents, or on-disk artifacts in this repo.

## A1) Repo map (top-level)

Top-level entries and their roles:

- `.git/`: Git metadata (not used by runtime code).
- `.pytest_cache/`: Local pytest cache (generated by tests).
- `checkpoints/`: Legacy (non-`run_id`) checkpoints written by `scripts/train_source.py` and `scripts/adapt_me_iis.py`.
- `clustering/`: Pluggable latent “style” clustering backends used by ME-IIS (`gmm` and `vmf_softmax`).
- `datasets/`: Dataset loader code for Office-Home and Office-31 (ImageFolder-based, class-aligned across domains).
- `docs/`: Repository documentation (`docs/cli_reference.md`, prior `docs/REPO_AUDIT.md`, and the docs produced by this task).
- `env/`: Requirements files and environment notes.
- `models/`: Model components (ResNet-50 backbone, classifier head, ME-IIS adapter/solver).
- `notebooks/`: Colab notebook(s) (`notebooks/Run_All_Experiments.ipynb`).
- `results/`: Legacy CSV logs and IIS artifacts (`.npz`) written by scripts.
- `scripts/`: CLI entrypoints for legacy training/adaptation/eval/ablations and utilities.
- `src/`: “Unified runner” implementation used by the notebook (deterministic `run_id`, per-run directories, baselines, checkpointing/state, evaluation harness).
- `tests/`: Unit/integration tests (runnable via `python -m pytest`).
- `utils/`: Small helpers (seeding, dataloader building, feature extraction, logging utilities, etc.).
- `eval.py`: Shared evaluation helper (`evaluate`, `predict_features`).
- `README.md`: Project overview + usage.
- `requirements.txt`: Minimal Python dependency set.
- `run_smoke_tests.py`: Smoke-test harness (compile + IIS sanity + dry-run train/adapt on a tiny synthetic dataset tree).

## A1) Entrypoints (exact)

### Source training (legacy script)
- Path: `scripts/train_source.py`
- Main entry: `train_source(args)`; CLI uses `src/cli/args.py:build_train_parser()`
- Key arguments (selected): `--dataset_name`, `--data_root`, `--source_domain`, `--target_domain`, `--num_epochs`, `--batch_size`, `--lr_backbone`, `--lr_classifier`, `--weight_decay`, `--resume_from`, `--save_every`, `--seed`, `--deterministic`, `--dry_run_max_batches`, `--dry_run_max_samples`
- Outputs:
  - Checkpoint: `utils/experiment_utils.py:build_source_ckpt_path(...)` → `checkpoints/source_only_{src}_to_{tgt}_seed{seed}.pth`
  - Optional epoch checkpoints: `checkpoints/source_only_{src}_to_{tgt}_seed{seed}_epoch{epoch}.pth`
  - TensorBoard: `runs/source_train` (via `torch.utils.tensorboard.SummaryWriter`)
  - Legacy results CSV: `results/office_home_me_iis.csv` via `utils/logging_utils.py:upsert_csv_row(...)`

### ME-IIS adaptation (legacy script)
- Path: `scripts/adapt_me_iis.py`
- Main entry: `adapt_me_iis(args)`; CLI uses `src/cli/args.py:build_adapt_parser()`
- Key arguments (selected): `--checkpoint`, `--feature_layers`, `--cluster_backend`, `--gmm_selection_mode`, `--gmm_bic_min_components`, `--gmm_bic_max_components`, `--num_latent_styles`, `--components_per_layer`, `--cluster_clean_ratio`, `--source_prob_mode`, `--iis_iters`, `--iis_tol`, `--adapt_epochs`, `--finetune_backbone`, `--backbone_lr_scale`, `--classifier_lr`, pseudo-label flags (`--use_pseudo_labels`, `--pseudo_*`), `--resume_adapt_from`, `--save_adapt_every`, dry-run flags
- Outputs:
  - Adapt checkpoint: `scripts/adapt_me_iis.py:_build_adapt_ckpt_path(...)` → `checkpoints/me_iis_{src}_to_{tgt}_{layer_tag}_seed{seed}.pth`
  - Optional epoch checkpoints: `..._epoch{epoch}.pth`
  - IIS history artifact: `results/me_iis_weights_{src}_to_{tgt}_{layer_tag}_seed{seed}_{run_id}.npz`
  - TensorBoard: `runs/adapt_me_iis`
  - Legacy results CSV: `results/office_home_me_iis.csv` via `utils/logging_utils.py:upsert_csv_row(...)`

### Evaluation
- Shared evaluator: `eval.py:evaluate(model, loader, device)` and `eval.py:predict_features(...)`
- Legacy eval entrypoint: `scripts/eval_source_only.py:eval_source_only(args)` (optional CSV upsert into `results/office_home_me_iis.csv` when `--append_results` is set)
- Unified evaluation harness: `src/experiments/eval_harness.py:evaluate_source_and_target(...)` used by `src/experiments/runner.py:run_one(...)` to write per-run `metrics.csv`

### Experiment runners
- Legacy ablation driver: `scripts/run_me_iis_experiments.py` (families: `layers`, `gmm`, `me_iis`)
  - Uses in-process calls to `scripts/train_source.py:train_source(...)` and `scripts/adapt_me_iis.py:adapt_me_iis(...)`
  - Reads `results/office_home_me_iis.csv` and resolves the expected row by `run_id`
  - Writes a summary CSV to `results/me_iis_experiments_summary.csv` by default
- Unified runner: `src/experiments/runner.py:run_one(config, ...)`
  - Runs methods in-process: `src/experiments/methods/source_only.py:run(...)`, `src/experiments/methods/me_iis.py:run(...)`, `src/experiments/methods/dann.py:run(...)`, `src/experiments/methods/coral.py:run(...)`, `src/experiments/methods/pseudo_label.py:run(...)`
  - Writes a deterministic run directory per config:
    - `src/experiments/run_config.py:get_run_dir(...)` → `outputs/runs/{dataset_tag}/{src}2{tgt}/{method}/{run_id}/`
    - `config.json` via `src/experiments/run_config.py:save_config(...)`
    - `state.json` via `src/experiments/checkpointing.py:save_state(...)`
    - `logs/stdout.txt`, `logs/stderr.txt` via `src/experiments/stream_capture.py:redirect_std_streams(...)`
    - checkpoints under `checkpoints/` via `src/experiments/run_artifacts.py:RunArtifacts`
    - `metrics.csv` via `src/experiments/metrics.py:write_metrics_csv(...)`
- Smoke tests: `run_smoke_tests.py:main()`

### Notebook(s)
- `notebooks/Run_All_Experiments.ipynb`: Colab notebook orchestrating the unified runner (see `docs/COLAB_AUDIT.md`).

### Tests
- Runner: `python -m pytest`
- Test directory: `tests/` (includes IIS math/unit tests, checkpoint resume tests, CLI arg parsing tests, clustering backend tests, etc.)

## A2) End-to-end trace (source training)

### Data loading (behavior, transforms, splits)
- Loader entrypoint: `datasets/domain_loaders.py:get_domain_loaders(...)`
- Dataset backend: `torchvision.datasets.ImageFolder`
- Transforms: `datasets/domain_loaders.py:_build_transforms(train=True|False)`
  - Train: `Resize(256) → RandomResizedCrop(224) → RandomHorizontalFlip() → ToTensor() → Normalize(IMAGENET_MEAN, IMAGENET_STD)`
  - Eval: `Resize(256) → CenterCrop(224) → ToTensor() → Normalize(...)`
- Class alignment:
  - Office-Home: `datasets/domain_loaders.py:_oh_build_shared_class_mapping(...)` ensures source/target have identical class folder names and identical `class_to_idx`
  - Office-31: `datasets/domain_loaders.py:_o31_build_shared_class_mapping(...)` similarly enforces class alignment
- Splits:
  - No explicit train/val split is created in this repo. The “target_eval_loader” is the target domain with eval transforms.

### Model architecture & initialization
- Model constructor: `models/classifier.py:build_model(num_classes, pretrained=True)`
  - Backbone: `models/backbone.py:ResNet50Backbone(pretrained=True)` using `torchvision.models.resnet50(weights=IMAGENET1K_V1)`
  - Head: `models/classifier.py:ClassifierHead` (single linear layer with Kaiming init)

### Optimizer + scheduler (legacy script)
- In `scripts/train_source.py:train_source(...)`:
  - Optimizer: SGD with momentum 0.9 and `weight_decay=args.weight_decay`
  - LR groups: backbone `args.lr_backbone`, classifier `args.lr_classifier`
  - Scheduler: `torch.optim.lr_scheduler.CosineAnnealingLR(T_max=args.num_epochs)`

### Checkpoint naming + resume behavior (legacy script)
- Canonical checkpoint: `checkpoints/source_only_{src}_to_{tgt}_seed{seed}.pth`
- Auto-resume behavior: if `args.resume_from` is empty and that checkpoint exists, `scripts/train_source.py` sets `args.resume_from` to that checkpoint.
- Resume loads:
  - `backbone` and `classifier` state dicts
  - optional `optimizer` and `scheduler` state dicts
  - epoch counters and best metrics (when present)

### Result logging
- Legacy results CSV: `results/office_home_me_iis.csv`
- Writer: `utils/logging_utils.py:upsert_csv_row(...)` keyed by `run_id` (see `src/experiments/legacy_results.py:legacy_train_payload(...)`)

## A2) End-to-end trace (adaptation: ME-IIS)

This section describes the actual ME-IIS implementation used by both:
- legacy script `scripts/adapt_me_iis.py`, and
- unified method `src/experiments/methods/me_iis.py` (the notebook uses the unified runner).

### Feature extraction (where, how)
- Function: `utils/feature_utils.py:extract_features(model, loader, device, feature_layers, max_batches=...)`
- Model call: `models/backbone.py:ResNet50Backbone.forward_intermediates(...)` via `models/backbone.py:FullModel.forward_with_intermediates(...)`
- Output:
  - `layer_feats`: dict `layer_name -> Tensor(N, D_layer)` (pooled vectors on CPU)
  - `logits`: Tensor(N, K) on CPU
  - `labels`: Tensor(N,) as produced by the DataLoader

### Layer selection
- Legacy script: parses `--feature_layers` via `utils/experiment_utils.py:parse_feature_layers(...)`
- Unified method: resolves layers from `config.method_params["feature_layers"]` (or falls back to `config.feature_layers`) in `src/experiments/methods/me_iis.py`
- Backbone supports: `models/backbone.py:SUPPORTED_LAYERS = ["layer1","layer2","layer3","layer4","avgpool"]`

### Clustering backend(s) and parameters
- Backend creation: `clustering/factory.py:create_backend(...)`
  - `gmm`: `clustering/gmm_backend.py:GMMBackend` (sklearn `GaussianMixture`; optional BIC selection)
  - `vmf_softmax`: `clustering/vmf_softmax_backend.py:VMFSoftmaxBackend` (KMeans prototypes on L2-normalized features + softmax with scale `kappa`)
- Fit location:
  - Legacy: `models/me_iis_adapter.py:MaxEntAdapter.fit_target_structure(...)`
  - Unified: same adapter class used inside `src/experiments/methods/me_iis.py`
- “Clean clustering” optional:
  - `models/me_iis_adapter.py:fit_target_structure(...)` uses `models/iis_components.py:TargetEntropyFilter` when `cluster_clean_ratio < 1.0`

### Style × class joint constraints (exact shapes)
- Built by: `models/iis_components.py:JointConstraintBuilder.build_joint(...)`
- Inputs:
  - responsibilities per layer: `gamma_t` with shape `(N, J_layer)` from `LatentBackend.predict_proba(...)`
  - class probabilities: `probs` with shape `(N, K)` (row-normalized)
- Output per layer:
  - `joint[layer] = gamma_t.unsqueeze(2) * probs.unsqueeze(1)`
  - Shape: `(N, J_layer, K)`
- Flattening:
  - `models/iis_components.py:ConstraintIndexer.flatten(...)` concatenates per-layer `(N, J_layer*K)` into `(N, C_total)`

### IIS loop (what updates each iteration; convergence)
- Solver: `models/me_iis_adapter.py:MaxEntAdapter.solve_iis(...)`
- Moments:
  - Target moments: `target_moments = IISUpdater.compute_pg(target_flat)` where `target_flat.shape == (N_t, C_total)`
  - Model moments: `pm = IISUpdater.compute_pm(weights, source_flat)` where `source_flat.shape == (N_s, C_total)` and `weights.shape == (N_s,)`
- Update per iteration:
  - `delta = IISUpdater.delta_lambda(pg, pm)` implements `Δλ = (1/(N_d+N_c)) * log(P_g / P_m)`
  - `weights ← IISUpdater.update_weights(weights, source_flat, delta)` implements `q_new ∝ q * exp(Σ_k f_k(t) * Δλ_k)`, then renormalizes to sum 1
- Convergence criteria:
  - Iterates `max_iter` times; early-stops if `iis_tol > 0` and `max_abs_moment_error < iis_tol`
- Diagnostics captured:
  - `models/me_iis_adapter.py:IISIterationStats` per iteration (moment errors, entropy, feature-mass stats, and `num_unachievable_constraints`)

### How weights are applied during training (loss weighting)
- Legacy: `scripts/adapt_me_iis.py:adapt_epoch(...)`
- Unified: `src/experiments/methods/me_iis.py:adapt_epoch(...)`
- Weighted source loss:
  - Compute per-sample CE with `reduction="none"`
  - Weight and normalize: `(w_i * ce_i).sum() / (w.sum() + 1e-8)`
- Target labels in UDA training:
  - Legacy script prints an audit line and deletes target labels before IIS (`scripts/adapt_me_iis.py`).
  - Unified methods use `src/experiments/data.py:DropLabelsDataset` and `src/experiments/data.py:assert_labels_dropped(...)` in baselines to enforce label dropping.

### Backbone frozen vs fine-tuned
- Legacy:
  - If `--finetune_backbone` is false, backbone params are set `requires_grad=False`
  - Optimizer LR: backbone group uses `classifier_lr * backbone_lr_scale` (only if finetuning)
- Unified:
  - Similar logic inside `src/experiments/methods/me_iis.py` (uses `config.finetune_backbone`, `config.backbone_lr_scale`, `config.classifier_lr`)

### Adaptation outputs + logging
- Legacy:
  - Checkpoints in `checkpoints/` (non-`run_id` naming)
  - IIS history `.npz` in `results/` (now includes `run_id` in the filename)
  - CSV row in `results/office_home_me_iis.csv` (keyed by `run_id`)
- Unified:
  - Per-run directory: `outputs/runs/.../{run_id}/`
  - IIS history `.npz`: `outputs/runs/.../{run_id}/checkpoints/me_iis_history_{run_id}.npz`
  - Metrics: `outputs/runs/.../{run_id}/metrics.csv` written by `src/experiments/runner.py`

## F) Unit tests (what is covered)

Test runner:
- `python -m pytest`

Coverage highlights (by test module intent):
- Data loader behavior / class alignment:
  - `tests/test_domain_loaders.py`
- IIS math + constraint construction:
  - `tests/test_clustering_backends.py` (mass property, Eq. (14)/(15) moment forms, Eq. (18) delta form, single-step update)
  - `tests/test_me_iis_additional.py` and `tests/test_iis_two_class_solution.py` (known-solution convergence, unreachable constraint behavior)
- Checkpointing / resume / skip:
  - Legacy script resume: `tests/test_checkpoints_resume.py`
  - Unified `run_id` + resume/skip: `tests/test_run_config_and_checkpointing.py`
- Logging integrity:
  - Legacy CSV idempotent upsert keyed by `run_id`: `tests/test_results_logging.py`
  - Notebook summary row status logic: `tests/test_results_logging.py`
- Baselines sanity:
  - DANN/CORAL related tests: `tests/test_dann_sanity.py`, `tests/test_coral_loss.py`
- CLI argument parsing / invalid flags:
  - `tests/test_cli_flags_*.py`, `tests/test_cli_invalid_args.py`

Most recent local run in this workspace:
- `python -m pytest -q` → `63 passed` (warnings include sklearn confusion-matrix shape warning for single-label batches in a dry-run test, and some PyTorch `assert_allclose` deprecation warnings).
