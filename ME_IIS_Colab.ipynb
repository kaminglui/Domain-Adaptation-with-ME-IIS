{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b34141f",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kaminglui/Domain-Adaptation-with-ME-IIS/blob/main/ME_IIS_Colab.ipynb\" target=\"_blank\">Open in Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c57dfc",
   "metadata": {},
   "source": [
    "# ME-IIS Domain Adaptation (Colab)\n",
    "Single-pass pipeline to train a source ResNet-50 and adapt with ME-IIS. Edit the Section 3 config cell to switch datasets, domains, and options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ffbda6",
   "metadata": {},
   "source": [
    "## 0. Setup & GPU check\n",
    "- Mount Google Drive and choose a working directory.\n",
    "- Clone/pull the repo into that folder.\n",
    "- Confirm CUDA availability and show the GPU name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 0 - Setup & GPU check\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "USE_DRIVE = True  # Set False to keep everything in /content\n",
    "DRIVE_ROOT = \"/content/drive/MyDrive\" if USE_DRIVE else \"/content\"\n",
    "WORK_DIR = os.path.join(DRIVE_ROOT, \"MEIIS-Colab\")\n",
    "REPO_URL = \"https://github.com/kaminglui/Domain-Adaptation-with-ME-IIS.git\"\n",
    "REPO_NAME = \"Domain-Adaptation-with-ME-IIS\"\n",
    "REPO_DIR = os.path.join(WORK_DIR, REPO_NAME)\n",
    "\n",
    "if USE_DRIVE:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "os.chdir(WORK_DIR)\n",
    "print(\"WORK_DIR:\", WORK_DIR)\n",
    "\n",
    "if not os.path.isdir(REPO_DIR):\n",
    "    print(\"[Repo] Cloning repository...\")\n",
    "    !git clone {REPO_URL}\n",
    "else:\n",
    "    print(\"[Repo] Repository exists; pulling latest changes...\")\n",
    "    os.chdir(REPO_DIR)\n",
    "    !git pull\n",
    "    os.chdir(WORK_DIR)\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print(\"[Repo] Current repo dir:\", os.getcwd())\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        print(\"GPU not detected - switch runtime to GPU for full runs.\")\n",
    "except ImportError as exc:\n",
    "    print(\"PyTorch not installed yet; run Section 1 to install dependencies. GPU check skipped:\", exc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125ea71",
   "metadata": {},
   "source": [
    "## 1. Install dependencies\n",
    "Re-run this cell if the Colab runtime restarts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae70533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1 - Install dependencies (re-run if the runtime restarts)\n",
    "import os\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "req_file = \"env/requirements_colab.txt\" if os.path.exists(\"env/requirements_colab.txt\") else \"env/requirements.txt\"\n",
    "print(\"Installing dependencies from:\", req_file)\n",
    "!pip install -r {req_file}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f45725f",
   "metadata": {},
   "source": [
    "## 2. Download datasets via KaggleHub\n",
    "Downloads Office-Home and Office-31 with KaggleHub, locates the canonical roots, and links them under `datasets/` for the scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2 - Download datasets via KaggleHub\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print(\"Repo dir:\", os.getcwd())\n",
    "\n",
    "try:\n",
    "    import kagglehub  # type: ignore\n",
    "except ImportError:\n",
    "    print(\"[Data] Installing kagglehub...\")\n",
    "    !pip install kagglehub\n",
    "    import kagglehub  # type: ignore\n",
    "\n",
    "def _find_office_home_root(base_dir: pathlib.Path) -> pathlib.Path:\n",
    "    candidates = [base_dir] + [p for p in base_dir.rglob(\"*\") if p.is_dir()]\n",
    "    for cand in candidates:\n",
    "        names = {p.name for p in cand.iterdir() if p.is_dir()}\n",
    "        if {\"Art\", \"Clipart\", \"Product\"} <= names and any(n.lower().startswith(\"real\") for n in names):\n",
    "            return cand\n",
    "    return base_dir\n",
    "\n",
    "def _find_office31_root(base_dir: pathlib.Path) -> pathlib.Path:\n",
    "    candidates = [base_dir] + [p for p in base_dir.rglob(\"*\") if p.is_dir()]\n",
    "    for cand in candidates:\n",
    "        names = {p.name.lower() for p in cand.iterdir() if p.is_dir()}\n",
    "        if {\"amazon\", \"dslr\", \"webcam\"} <= names:\n",
    "            return cand\n",
    "    return base_dir\n",
    "\n",
    "print(\"[Data] Downloading Office-Home (lhrrraname/officehome)...\")\n",
    "office_home_raw = pathlib.Path(kagglehub.dataset_download(\"lhrrraname/officehome\"))\n",
    "office_home_root = _find_office_home_root(office_home_raw)\n",
    "print(\"  Office-Home root:\", office_home_root)\n",
    "\n",
    "print(\"[Data] Downloading Office-31 (xixuhu/office31)...\")\n",
    "office31_raw = pathlib.Path(kagglehub.dataset_download(\"xixuhu/office31\"))\n",
    "office31_root = _find_office31_root(office31_raw)\n",
    "print(\"  Office-31 root:\", office31_root)\n",
    "\n",
    "datasets_dir = pathlib.Path(\"datasets\")\n",
    "datasets_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def _ensure_link(link_path: pathlib.Path, target: pathlib.Path) -> None:\n",
    "    target = target.resolve()\n",
    "    if link_path.exists() and not link_path.is_symlink():\n",
    "        print(f\"[Data] {link_path} exists and is not a symlink; leaving as-is.\")\n",
    "        return\n",
    "    if link_path.is_symlink():\n",
    "        current = link_path.resolve()\n",
    "        if current == target:\n",
    "            print(f\"[Data] {link_path} already points to {target}\")\n",
    "            return\n",
    "        link_path.unlink()\n",
    "    try:\n",
    "        link_path.symlink_to(target, target_is_directory=True)\n",
    "        print(f\"[Data] Linked {link_path} -> {target}\")\n",
    "    except OSError as exc:\n",
    "        print(f\"[Data] Could not create symlink {link_path} -> {target}: {exc}\")\n",
    "\n",
    "_ensure_link(datasets_dir / \"Office-Home\", office_home_root)\n",
    "_ensure_link(datasets_dir / \"Office-31\", office31_root)\n",
    "\n",
    "OFFICE_HOME_ROOT = datasets_dir / \"Office-Home\"\n",
    "OFFICE31_ROOT = datasets_dir / \"Office-31\"\n",
    "print(\"[Data] Office-Home DATA_ROOT:\", OFFICE_HOME_ROOT)\n",
    "print(\"[Data] Office-31 DATA_ROOT:\", OFFICE31_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff21e55",
   "metadata": {},
   "source": [
    "## 3. Configuration (single cell with all knobs)\n",
    "Edit only in this cell to change experiment settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit only in this cell to change experiment settings.\n",
    "\n",
    "# Dataset & domains\n",
    "DATASET_NAME = \"office_home\"  # or \"office31\"\n",
    "SOURCE_DOMAIN = \"Ar\"          # e.g. Ar/Cl/Pr/Rw for Office-Home, A/D/W for Office-31\n",
    "TARGET_DOMAIN = \"Cl\"\n",
    "SEED = 0\n",
    "\n",
    "# Paths (assume we are in the repo root)\n",
    "DATA_ROOT = \"datasets/Office-Home\"  # or \"datasets/Office-31\"\n",
    "\n",
    "# Source training hyperparameters\n",
    "NUM_EPOCHS_SRC = 50\n",
    "BATCH_SIZE_SRC = 32\n",
    "LR_BACKBONE = 1e-3\n",
    "LR_CLASSIFIER = 1e-2\n",
    "WEIGHT_DECAY = 1e-3\n",
    "NUM_WORKERS = 4\n",
    "DETERMINISTIC = True  # set True to minimize randomness\n",
    "\n",
    "# ME-IIS / adaptation hyperparameters\n",
    "FEATURE_LAYERS = \"layer3,layer4,avgpool\"\n",
    "GMM_SELECTION_MODE = \"bic\"        # \"fixed\" or \"bic\"\n",
    "NUM_LATENT_STYLES = 5             # default components per layer (fixed mode or BIC init)\n",
    "GMM_BIC_MIN_COMPONENTS = 2        # BIC lower bound\n",
    "GMM_BIC_MAX_COMPONENTS = 8        # BIC upper bound\n",
    "\n",
    "# NEW: source_prob_mode\n",
    "SOURCE_PROB_MODE = \"softmax\"      # or \"onehot\" (use GT labels for source constraints)\n",
    "\n",
    "# NEW: optional per-layer GMM override\n",
    "# e.g. \"layer3:10,layer4:5\" or \"7,8,9\" for 3 layers; leave \"\" to disable\n",
    "COMPONENTS_OVERRIDE = \"\"\n",
    "\n",
    "# Pseudo-label adaptation (ME-IIS+PL)\n",
    "USE_PSEUDO_LABELS = False         # default False; set True to use pseudo-labels\n",
    "PSEUDO_CONF_THRESH = 0.9\n",
    "PSEUDO_MAX_RATIO = 1.0            # 1.0 = no cap; or e.g. 0.3 to limit pseudo-target count\n",
    "PSEUDO_LOSS_WEIGHT = 1.0\n",
    "\n",
    "# IIS configuration\n",
    "IIS_ITERS = 15\n",
    "IIS_TOL = 1e-3\n",
    "ADAPT_EPOCHS = 10\n",
    "FINETUNE_BACKBONE = False\n",
    "BACKBONE_LR_SCALE = 0.1\n",
    "CLASSIFIER_LR = 1e-2\n",
    "ADAPT_WEIGHT_DECAY = 1e-3\n",
    "\n",
    "# Optional: force fresh runs instead of auto-resume\n",
    "FORCE_FRESH_SOURCE_TRAIN = False\n",
    "FORCE_FRESH_ADAPT = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d56b10e",
   "metadata": {},
   "source": [
    "## 4. Helper: construct checkpoint paths and cleanup\n",
    "Lets you intentionally bypass auto-resume by deleting existing checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dffbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "def get_source_ckpt_path():\n",
    "    return f\"checkpoints/source_only_{SOURCE_DOMAIN}_to_{TARGET_DOMAIN}_seed{SEED}.pth\"\n",
    "\n",
    "def get_me_iis_ckpt_path():\n",
    "    layers_str = FEATURE_LAYERS.replace(\",\", \"-\").replace(\" \", \"\")\n",
    "    return f\"checkpoints/me_iis_{SOURCE_DOMAIN}_to_{TARGET_DOMAIN}_{layers_str}_seed{SEED}.pth\"\n",
    "\n",
    "if FORCE_FRESH_SOURCE_TRAIN:\n",
    "    src_ckpt = get_source_ckpt_path()\n",
    "    if os.path.exists(src_ckpt):\n",
    "        os.remove(src_ckpt)\n",
    "        print(\"Deleted existing source checkpoint:\", src_ckpt)\n",
    "\n",
    "if FORCE_FRESH_ADAPT:\n",
    "    adapt_ckpt = get_me_iis_ckpt_path()\n",
    "    if os.path.exists(adapt_ckpt):\n",
    "        os.remove(adapt_ckpt)\n",
    "        print(\"Deleted existing ME-IIS checkpoint:\", adapt_ckpt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7407a",
   "metadata": {},
   "source": [
    "## 5. Train source-only model (full training)\n",
    "Build the command from the config above and stream output directly in the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b30bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "det_flag = \"--deterministic\" if DETERMINISTIC else \"\"\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "SRC_CMD = (\n",
    "    'python scripts/train_source.py \\\n",
    "'\n",
    "    f'  --dataset_name {DATASET_NAME} \\\n",
    "'\n",
    "    f'  --data_root \"{DATA_ROOT}\" \\\n",
    "'\n",
    "    f'  --source_domain {SOURCE_DOMAIN} \\\n",
    "'\n",
    "    f'  --target_domain {TARGET_DOMAIN} \\\n",
    "'\n",
    "    f'  --num_epochs {NUM_EPOCHS_SRC} \\\n",
    "'\n",
    "    f'  --batch_size {BATCH_SIZE_SRC} \\\n",
    "'\n",
    "    f'  --lr_backbone {LR_BACKBONE} \\\n",
    "'\n",
    "    f'  --lr_classifier {LR_CLASSIFIER} \\\n",
    "'\n",
    "    f'  --weight_decay {WEIGHT_DECAY} \\\n",
    "'\n",
    "    f'  --num_workers {NUM_WORKERS} \\\n",
    "'\n",
    "    f'  {det_flag} \\\n",
    "'\n",
    "    f'  --seed {SEED}'\n",
    ").strip()\n",
    "\n",
    "print(\"Training command:\\n\", SRC_CMD)\n",
    "!{SRC_CMD}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0d371b",
   "metadata": {},
   "source": [
    "## 6. Run ME-IIS adaptation\n",
    "Uses the source checkpoint above plus the ME-IIS settings in the config cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ccabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "det_flag = \"--deterministic\" if DETERMINISTIC else \"\"\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "ADAPT_CMD = (\n",
    "    'python scripts/adapt_me_iis.py \\\n",
    "'\n",
    "    f'  --dataset_name {DATASET_NAME} \\\n",
    "'\n",
    "    f'  --data_root \"{DATA_ROOT}\" \\\n",
    "'\n",
    "    f'  --source_domain {SOURCE_DOMAIN} \\\n",
    "'\n",
    "    f'  --target_domain {TARGET_DOMAIN} \\\n",
    "'\n",
    "    f'  --checkpoint {get_source_ckpt_path()} \\\n",
    "'\n",
    "    f'  --batch_size {BATCH_SIZE_SRC} \\\n",
    "'\n",
    "    f'  --num_workers {NUM_WORKERS} \\\n",
    "'\n",
    "    f'  --feature_layers \"{FEATURE_LAYERS}\" \\\n",
    "'\n",
    "    f'  --num_latent_styles {NUM_LATENT_STYLES} \\\n",
    "'\n",
    "    f'  --gmm_selection_mode {GMM_SELECTION_MODE} \\\n",
    "'\n",
    "    f'  --gmm_bic_min_components {GMM_BIC_MIN_COMPONENTS} \\\n",
    "'\n",
    "    f'  --gmm_bic_max_components {GMM_BIC_MAX_COMPONENTS} \\\n",
    "'\n",
    "    f'  --iis_iters {IIS_ITERS} \\\n",
    "'\n",
    "    f'  --iis_tol {IIS_TOL} \\\n",
    "'\n",
    "    f'  --adapt_epochs {ADAPT_EPOCHS} \\\n",
    "'\n",
    "    f'  {'--finetune_backbone' if FINETUNE_BACKBONE else ''} \\\n",
    "'\n",
    "    f'  --backbone_lr_scale {BACKBONE_LR_SCALE} \\\n",
    "'\n",
    "    f'  --classifier_lr {CLASSIFIER_LR} \\\n",
    "'\n",
    "    f'  --weight_decay {ADAPT_WEIGHT_DECAY} \\\n",
    "'\n",
    "    f'  --source_prob_mode {SOURCE_PROB_MODE} \\\n",
    "'\n",
    "    f'  {det_flag} \\\n",
    "'\n",
    "    f'  --seed {SEED}'\n",
    ").strip()\n",
    "\n",
    "if USE_PSEUDO_LABELS:\n",
    "    ADAPT_CMD += (\n",
    "        f\" --use_pseudo_labels --pseudo_conf_thresh {PSEUDO_CONF_THRESH} \"\n",
    "        f\"--pseudo_max_ratio {PSEUDO_MAX_RATIO} --pseudo_loss_weight {PSEUDO_LOSS_WEIGHT}\"\n",
    "    )\n",
    "\n",
    "if COMPONENTS_OVERRIDE.strip():\n",
    "    ADAPT_CMD += f' --components_per_layer \"{COMPONENTS_OVERRIDE}\"'\n",
    "\n",
    "print(\"Adaptation command:\\n\", ADAPT_CMD)\n",
    "!{ADAPT_CMD}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ccf29",
   "metadata": {},
   "source": [
    "## 7. Optional: experiment driver examples\n",
    "Leave `RUN_EXPERIMENT_DRIVER = False` for the standard train + adapt path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4236ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_EXPERIMENT_DRIVER = False\n",
    "\n",
    "if RUN_EXPERIMENT_DRIVER:\n",
    "    import os\n",
    "    os.chdir(REPO_DIR)\n",
    "    det_flag = \"--deterministic\" if DETERMINISTIC else \"\"\n",
    "    EXP_CMD = (\n",
    "        'python scripts/run_me_iis_experiments.py \\\n",
    "'\n",
    "        f'  --dataset_name {DATASET_NAME} \\\n",
    "'\n",
    "        f'  --source_domain {SOURCE_DOMAIN} \\\n",
    "'\n",
    "        f'  --target_domain {TARGET_DOMAIN} \\\n",
    "'\n",
    "        '  --experiment_family layers \\\n",
    "'\n",
    "        f'  --seeds {SEED} \\\n",
    "'\n",
    "        f'  --base_data_root \"{DATA_ROOT}\" \\\n",
    "'\n",
    "        f'  --feature_layers \"{FEATURE_LAYERS}\" \\\n",
    "'\n",
    "        f'  --num_latent_styles {NUM_LATENT_STYLES} \\\n",
    "'\n",
    "        f'  --gmm_selection_mode {GMM_SELECTION_MODE} \\\n",
    "'\n",
    "        f'  --gmm_bic_min_components {GMM_BIC_MIN_COMPONENTS} \\\n",
    "'\n",
    "        f'  --gmm_bic_max_components {GMM_BIC_MAX_COMPONENTS} \\\n",
    "'\n",
    "        f'  --source_prob_mode {SOURCE_PROB_MODE} \\\n",
    "'\n",
    "        f'  --num_epochs {NUM_EPOCHS_SRC} \\\n",
    "'\n",
    "        f'  --batch_size {BATCH_SIZE_SRC} \\\n",
    "'\n",
    "        f'  --num_workers {NUM_WORKERS} \\\n",
    "'\n",
    "        f'  --iis_iters {IIS_ITERS} \\\n",
    "'\n",
    "        f'  --iis_tol {IIS_TOL} \\\n",
    "'\n",
    "        f'  --adapt_epochs {ADAPT_EPOCHS} \\\n",
    "'\n",
    "        f'  --backbone_lr_scale {BACKBONE_LR_SCALE} \\\n",
    "'\n",
    "        f'  --classifier_lr {CLASSIFIER_LR} \\\n",
    "'\n",
    "        f'  --weight_decay {ADAPT_WEIGHT_DECAY} \\\n",
    "'\n",
    "        f'  {'--finetune_backbone' if FINETUNE_BACKBONE else ''} \\\n",
    "'\n",
    "        f'  {det_flag} \\\n",
    "'\n",
    "        f'  --output_csv results/me_iis_layers_{SOURCE_DOMAIN}_to_{TARGET_DOMAIN}_seed{SEED}.csv'\n",
    "    ).strip()\n",
    "\n",
    "    if COMPONENTS_OVERRIDE.strip():\n",
    "        EXP_CMD += f' --components_per_layer \"{COMPONENTS_OVERRIDE}\"'\n",
    "\n",
    "    if USE_PSEUDO_LABELS:\n",
    "        EXP_CMD += (\n",
    "            f\" --pseudo_conf_thresh {PSEUDO_CONF_THRESH} \"\n",
    "            f\"--pseudo_max_ratio {PSEUDO_MAX_RATIO} --pseudo_loss_weight {PSEUDO_LOSS_WEIGHT}\"\n",
    "        )\n",
    "\n",
    "    if det_flag:\n",
    "        EXP_CMD += f\" {det_flag}\"\n",
    "\n",
    "    print(\"Experiment driver command:\\n\", EXP_CMD)\n",
    "    !{EXP_CMD}\n",
    "else:\n",
    "    print(\"Experiment driver is disabled (set RUN_EXPERIMENT_DRIVER = True to run).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb1c47",
   "metadata": {},
   "source": [
    "## 8. Notes on outputs\n",
    "- Source checkpoints: `checkpoints/source_only_*` (auto-resume uses the matching file name).\n",
    "- ME-IIS checkpoints and IIS weights: `checkpoints/me_iis_*` and `results/me_iis_weights_*.npz`.\n",
    "- CSV log of source/adapt runs: `results/office_home_me_iis.csv` (dataset column distinguishes Office-Home vs Office-31).\n",
    "- Experiment driver summaries (optional): `results/me_iis_experiments_summary.csv` or the path you pass via `--output_csv`.\n",
    "- TensorBoard logs live under `runs/` (`runs/source_only` and `runs/adapt_me_iis`)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
