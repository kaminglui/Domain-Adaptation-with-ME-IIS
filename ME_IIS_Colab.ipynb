{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaminglui/Domain-Adaptation-with-ME-IIS/blob/main/ME_IIS_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3c57dfc",
      "metadata": {
        "id": "f3c57dfc"
      },
      "source": [
        "# ME-IIS Domain Adaptation (Colab)\n",
        "Single-pass pipeline to train a source ResNet-50 and adapt with ME-IIS. Edit the Section 3 config cell to switch datasets, domains, and options."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71ffbda6",
      "metadata": {
        "id": "71ffbda6"
      },
      "source": [
        "## 0. Setup & GPU check\n",
        "- Mount Google Drive and choose a working directory.\n",
        "- Clone/pull the repo into that folder.\n",
        "- Confirm CUDA availability and show the GPU name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "99e1d3bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99e1d3bf",
        "outputId": "7cff1547-b238-44d9-9107-cd5ca3d9593c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "WORK_DIR: /content/drive/MyDrive/MEIIS-Colab\n",
            "[Repo] Repository exists; pulling latest changes...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 48 (delta 31), reused 32 (delta 18), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (48/48), 51.75 KiB | 13.00 KiB/s, done.\n",
            "From https://github.com/kaminglui/Domain-Adaptation-with-ME-IIS\n",
            "   3459174..761a61e  main       -> origin/main\n",
            "Updating 3459174..761a61e\n",
            "Fast-forward\n",
            " ME_IIS_Colab.ipynb                | 559 \u001b[32m++++++++++++++++++++++++++++++++++++++\u001b[m\n",
            " README.md                         |  13 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " datasets/domain_loaders.py        |  68 \u001b[32m++++\u001b[m\u001b[31m-\u001b[m\n",
            " models/me_iis_adapter.py          | 100 \u001b[32m++++++\u001b[m\u001b[31m-\u001b[m\n",
            " run_smoke_tests.py                | 274 \u001b[32m+++++++++++++\u001b[m\u001b[31m------\u001b[m\n",
            " scripts/adapt_me_iis.py           | 102 \u001b[32m++\u001b[m\u001b[31m-----\u001b[m\n",
            " scripts/demo_me_iis_toy.py        |  71 \u001b[32m+++++\u001b[m\n",
            " scripts/plot_iis_dynamics.py      |  23 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " scripts/run_me_iis_experiments.py | 516 \u001b[32m+++++++++++++++++++++++++++++++++++\u001b[m\n",
            " scripts/train_source.py           |  37 \u001b[32m+\u001b[m\u001b[31m--\u001b[m\n",
            " tests/test_experiment_utils.py    |  84 \u001b[32m++++++\u001b[m\n",
            " tests/test_me_iis_additional.py   | 184 \u001b[32m++++++++++++\u001b[m\u001b[31m-\u001b[m\n",
            " utils/experiment_utils.py         | 120 \u001b[32m++++++++\u001b[m\n",
            " utils/feature_utils.py            |  49 \u001b[32m++++\u001b[m\n",
            " 14 files changed, 1994 insertions(+), 206 deletions(-)\n",
            " create mode 100644 ME_IIS_Colab.ipynb\n",
            " create mode 100644 scripts/demo_me_iis_toy.py\n",
            " create mode 100644 scripts/run_me_iis_experiments.py\n",
            " create mode 100644 tests/test_experiment_utils.py\n",
            " create mode 100644 utils/experiment_utils.py\n",
            " create mode 100644 utils/feature_utils.py\n",
            "[Repo] Current repo dir: /content/drive/MyDrive/MEIIS-Colab/Domain-Adaptation-with-ME-IIS\n",
            "torch.cuda.is_available(): True\n",
            "GPU: NVIDIA L4\n"
          ]
        }
      ],
      "source": [
        "# Section 0 - Setup & GPU check\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "USE_DRIVE = True  # Set False to keep everything in /content\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive\" if USE_DRIVE else \"/content\"\n",
        "WORK_DIR = os.path.join(DRIVE_ROOT, \"MEIIS-Colab\")\n",
        "REPO_URL = \"https://github.com/kaminglui/Domain-Adaptation-with-ME-IIS.git\"\n",
        "REPO_NAME = \"Domain-Adaptation-with-ME-IIS\"\n",
        "REPO_DIR = os.path.join(WORK_DIR, REPO_NAME)\n",
        "\n",
        "if USE_DRIVE:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "os.chdir(WORK_DIR)\n",
        "print(\"WORK_DIR:\", WORK_DIR)\n",
        "\n",
        "if not os.path.isdir(REPO_DIR):\n",
        "    print(\"[Repo] Cloning repository...\")\n",
        "    !git clone {REPO_URL}\n",
        "else:\n",
        "    print(\"[Repo] Repository exists; pulling latest changes...\")\n",
        "    os.chdir(REPO_DIR)\n",
        "    !git pull\n",
        "    os.chdir(WORK_DIR)\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"[Repo] Current repo dir:\", os.getcwd())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "    else:\n",
        "        print(\"GPU not detected - switch runtime to GPU for full runs.\")\n",
        "except ImportError as exc:\n",
        "    print(\"PyTorch not installed yet; run Section 1 to install dependencies. GPU check skipped:\", exc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3125ea71",
      "metadata": {
        "id": "3125ea71"
      },
      "source": [
        "## 1. Install dependencies\n",
        "Re-run this cell if the Colab runtime restarts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5ae70533",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ae70533",
        "outputId": "c83ea5b8-7c47-467a-a4ed-48aa88338033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies from: env/requirements_colab.txt\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r env/requirements_colab.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r env/requirements_colab.txt (line 2)) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r env/requirements_colab.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from -r env/requirements_colab.txt (line 4)) (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r env/requirements_colab.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r env/requirements_colab.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r env/requirements_colab.txt (line 7)) (2.19.0)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (from -r env/requirements_colab.txt (line 8)) (0.3.13)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r env/requirements_colab.txt (line 2)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r env/requirements_colab.txt (line 2)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r env/requirements_colab.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r env/requirements_colab.txt (line 5)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r env/requirements_colab.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r env/requirements_colab.txt (line 5)) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r env/requirements_colab.txt (line 5)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r env/requirements_colab.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r env/requirements_colab.txt (line 5)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r env/requirements_colab.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r env/requirements_colab.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r env/requirements_colab.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r env/requirements_colab.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r env/requirements_colab.txt (line 7)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r env/requirements_colab.txt (line 7)) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r env/requirements_colab.txt (line 7)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r env/requirements_colab.txt (line 7)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r env/requirements_colab.txt (line 7)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r env/requirements_colab.txt (line 7)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r env/requirements_colab.txt (line 7)) (3.1.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub->-r env/requirements_colab.txt (line 8)) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub->-r env/requirements_colab.txt (line 8)) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard->-r env/requirements_colab.txt (line 7)) (4.15.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->-r env/requirements_colab.txt (line 7)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub->-r env/requirements_colab.txt (line 8)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub->-r env/requirements_colab.txt (line 8)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub->-r env/requirements_colab.txt (line 8)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub->-r env/requirements_colab.txt (line 8)) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "# Section 1 - Install dependencies (re-run if the runtime restarts)\n",
        "import os\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "req_file = \"env/requirements_colab.txt\" if os.path.exists(\"env/requirements_colab.txt\") else \"env/requirements.txt\"\n",
        "print(\"Installing dependencies from:\", req_file)\n",
        "!pip install -r {req_file}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f45725f",
      "metadata": {
        "id": "4f45725f"
      },
      "source": [
        "## 2. Download datasets via KaggleHub\n",
        "Downloads Office-Home and Office-31 with KaggleHub, locates the canonical roots, and links them under `datasets/` for the scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bd7b9957",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd7b9957",
        "outputId": "a571e358-b67b-438d-b2aa-650a34608934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repo dir: /content/drive/MyDrive/MEIIS-Colab/Domain-Adaptation-with-ME-IIS\n",
            "[Data] Downloading Office-Home (lhrrraname/officehome)...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/lhrrraname/officehome?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.06G/1.06G [00:13<00:00, 84.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Office-Home root: /root/.cache/kagglehub/datasets/lhrrraname/officehome/versions/1/datasets/OfficeHomeDataset_10072016\n",
            "[Data] Downloading Office-31 (xixuhu/office31)...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/xixuhu/office31?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75.9M/75.9M [00:00<00:00, 93.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Office-31 root: /root/.cache/kagglehub/datasets/xixuhu/office31/versions/1/Office-31\n",
            "[Data] Linked datasets/Office-Home -> /root/.cache/kagglehub/datasets/lhrrraname/officehome/versions/1/datasets/OfficeHomeDataset_10072016\n",
            "[Data] Linked datasets/Office-31 -> /root/.cache/kagglehub/datasets/xixuhu/office31/versions/1/Office-31\n",
            "[Data] Office-Home DATA_ROOT: datasets/Office-Home\n",
            "[Data] Office-31 DATA_ROOT: datasets/Office-31\n"
          ]
        }
      ],
      "source": [
        "# Section 2 - Download datasets via KaggleHub\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"Repo dir:\", os.getcwd())\n",
        "\n",
        "try:\n",
        "    import kagglehub  # type: ignore\n",
        "except ImportError:\n",
        "    print(\"[Data] Installing kagglehub...\")\n",
        "    !pip install kagglehub\n",
        "    import kagglehub  # type: ignore\n",
        "\n",
        "def _find_office_home_root(base_dir: pathlib.Path) -> pathlib.Path:\n",
        "    candidates = [base_dir] + [p for p in base_dir.rglob(\"*\") if p.is_dir()]\n",
        "    for cand in candidates:\n",
        "        names = {p.name for p in cand.iterdir() if p.is_dir()}\n",
        "        if {\"Art\", \"Clipart\", \"Product\"} <= names and any(n.lower().startswith(\"real\") for n in names):\n",
        "            return cand\n",
        "    return base_dir\n",
        "\n",
        "def _find_office31_root(base_dir: pathlib.Path) -> pathlib.Path:\n",
        "    candidates = [base_dir] + [p for p in base_dir.rglob(\"*\") if p.is_dir()]\n",
        "    for cand in candidates:\n",
        "        names = {p.name.lower() for p in cand.iterdir() if p.is_dir()}\n",
        "        if {\"amazon\", \"dslr\", \"webcam\"} <= names:\n",
        "            return cand\n",
        "    return base_dir\n",
        "\n",
        "print(\"[Data] Downloading Office-Home (lhrrraname/officehome)...\")\n",
        "office_home_raw = pathlib.Path(kagglehub.dataset_download(\"lhrrraname/officehome\"))\n",
        "office_home_root = _find_office_home_root(office_home_raw)\n",
        "print(\"  Office-Home root:\", office_home_root)\n",
        "\n",
        "print(\"[Data] Downloading Office-31 (xixuhu/office31)...\")\n",
        "office31_raw = pathlib.Path(kagglehub.dataset_download(\"xixuhu/office31\"))\n",
        "office31_root = _find_office31_root(office31_raw)\n",
        "print(\"  Office-31 root:\", office31_root)\n",
        "\n",
        "datasets_dir = pathlib.Path(\"datasets\")\n",
        "datasets_dir.mkdir(exist_ok=True)\n",
        "\n",
        "def _ensure_link(link_path: pathlib.Path, target: pathlib.Path) -> None:\n",
        "    target = target.resolve()\n",
        "    if link_path.exists() and not link_path.is_symlink():\n",
        "        print(f\"[Data] {link_path} exists and is not a symlink; leaving as-is.\")\n",
        "        return\n",
        "    if link_path.is_symlink():\n",
        "        current = link_path.resolve()\n",
        "        if current == target:\n",
        "            print(f\"[Data] {link_path} already points to {target}\")\n",
        "            return\n",
        "        link_path.unlink()\n",
        "    try:\n",
        "        link_path.symlink_to(target, target_is_directory=True)\n",
        "        print(f\"[Data] Linked {link_path} -> {target}\")\n",
        "    except OSError as exc:\n",
        "        print(f\"[Data] Could not create symlink {link_path} -> {target}: {exc}\")\n",
        "\n",
        "_ensure_link(datasets_dir / \"Office-Home\", office_home_root)\n",
        "_ensure_link(datasets_dir / \"Office-31\", office31_root)\n",
        "\n",
        "OFFICE_HOME_ROOT = datasets_dir / \"Office-Home\"\n",
        "OFFICE31_ROOT = datasets_dir / \"Office-31\"\n",
        "print(\"[Data] Office-Home DATA_ROOT:\", OFFICE_HOME_ROOT)\n",
        "print(\"[Data] Office-31 DATA_ROOT:\", OFFICE31_ROOT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ff21e55",
      "metadata": {
        "id": "7ff21e55"
      },
      "source": [
        "## 3. Configuration (single cell with all knobs)\n",
        "Edit only in this cell to change experiment settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "361d1911",
      "metadata": {
        "id": "361d1911"
      },
      "outputs": [],
      "source": [
        "# Edit only in this cell to change experiment settings.\n",
        "\n",
        "# Dataset & domains\n",
        "DATASET_NAME = \"office_home\"  # or \"office31\"\n",
        "SOURCE_DOMAIN = \"Ar\"          # e.g. Ar/Cl/Pr/Rw for Office-Home, A/D/W for Office-31\n",
        "TARGET_DOMAIN = \"Cl\"\n",
        "SEED = 0\n",
        "\n",
        "# Paths (assume we are in the repo root)\n",
        "DATA_ROOT = \"datasets/Office-Home\"  # or \"datasets/Office-31\"\n",
        "\n",
        "# Source training hyperparameters\n",
        "NUM_EPOCHS_SRC = 100\n",
        "BATCH_SIZE_SRC = 32\n",
        "LR_BACKBONE = 1e-3\n",
        "LR_CLASSIFIER = 1e-2\n",
        "WEIGHT_DECAY = 1e-3\n",
        "NUM_WORKERS = 4\n",
        "DETERMINISTIC = True  # set True to minimize randomness\n",
        "\n",
        "# ME-IIS / adaptation hyperparameters\n",
        "FEATURE_LAYERS = \"layer3,layer4,avgpool\"\n",
        "GMM_SELECTION_MODE = \"bic\"        # \"fixed\" or \"bic\"\n",
        "NUM_LATENT_STYLES = 5             # default components per layer (fixed mode or BIC init)\n",
        "GMM_BIC_MIN_COMPONENTS = 2        # BIC lower bound\n",
        "GMM_BIC_MAX_COMPONENTS = 8        # BIC upper bound\n",
        "\n",
        "# NEW: source_prob_mode\n",
        "SOURCE_PROB_MODE = \"softmax\"      # or \"onehot\" (use GT labels for source constraints)\n",
        "\n",
        "# NEW: optional per-layer GMM override\n",
        "# e.g. \"layer3:10,layer4:5\" or \"7,8,9\" for 3 layers; leave \"\" to disable\n",
        "COMPONENTS_OVERRIDE = \"\"\n",
        "\n",
        "# Pseudo-label adaptation (ME-IIS+PL)\n",
        "USE_PSEUDO_LABELS = False         # default False; set True to use pseudo-labels\n",
        "PSEUDO_CONF_THRESH = 0.9\n",
        "PSEUDO_MAX_RATIO = 1.0            # 1.0 = no cap; or e.g. 0.3 to limit pseudo-target count\n",
        "PSEUDO_LOSS_WEIGHT = 1.0\n",
        "\n",
        "# IIS configuration\n",
        "IIS_ITERS = 15\n",
        "IIS_TOL = 1e-3\n",
        "ADAPT_EPOCHS = 10\n",
        "FINETUNE_BACKBONE = False\n",
        "BACKBONE_LR_SCALE = 0.1\n",
        "CLASSIFIER_LR = 1e-2\n",
        "ADAPT_WEIGHT_DECAY = 1e-3\n",
        "\n",
        "# Optional: force fresh runs instead of auto-resume\n",
        "FORCE_FRESH_SOURCE_TRAIN = False\n",
        "FORCE_FRESH_ADAPT = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d56b10e",
      "metadata": {
        "id": "3d56b10e"
      },
      "source": [
        "## 4. Helper: construct checkpoint paths and cleanup\n",
        "Lets you intentionally bypass auto-resume by deleting existing checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dffbde8",
      "metadata": {
        "id": "1dffbde8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "def get_source_ckpt_path():\n",
        "    return f\"checkpoints/source_only_{SOURCE_DOMAIN}_to_{TARGET_DOMAIN}_seed{SEED}.pth\"\n",
        "\n",
        "def get_me_iis_ckpt_path():\n",
        "    layers_str = FEATURE_LAYERS.replace(\",\", \"-\").replace(\" \", \"\")\n",
        "    return f\"checkpoints/me_iis_{SOURCE_DOMAIN}_to_{TARGET_DOMAIN}_{layers_str}_seed{SEED}.pth\"\n",
        "\n",
        "if FORCE_FRESH_SOURCE_TRAIN:\n",
        "    src_ckpt = get_source_ckpt_path()\n",
        "    if os.path.exists(src_ckpt):\n",
        "        os.remove(src_ckpt)\n",
        "        print(\"Deleted existing source checkpoint:\", src_ckpt)\n",
        "\n",
        "if FORCE_FRESH_ADAPT:\n",
        "    adapt_ckpt = get_me_iis_ckpt_path()\n",
        "    if os.path.exists(adapt_ckpt):\n",
        "        os.remove(adapt_ckpt)\n",
        "        print(\"Deleted existing ME-IIS checkpoint:\", adapt_ckpt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09d7407a",
      "metadata": {
        "id": "09d7407a"
      },
      "source": [
        "## 5. Train source-only model (full training)\n",
        "Build the command from the config above and stream output directly in the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b30bd1",
      "metadata": {
        "id": "b3b30bd1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "det_flag = \"--deterministic\" if DETERMINISTIC else \"\"\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "SRC_CMD = (\n",
        "    'python scripts/train_source.py \\\n",
        "'\n",
        "    f'  --dataset_name {DATASET_NAME} \\\n",
        "'\n",
        "    f'  --data_root \"{DATA_ROOT}\" \\\n",
        "'\n",
        "    f'  --source_domain {SOURCE_DOMAIN} \\\n",
        "'\n",
        "    f'  --target_domain {TARGET_DOMAIN} \\\n",
        "'\n",
        "    f'  --num_epochs {NUM_EPOCHS_SRC} \\\n",
        "'\n",
        "    f'  --batch_size {BATCH_SIZE_SRC} \\\n",
        "'\n",
        "    f'  --lr_backbone {LR_BACKBONE} \\\n",
        "'\n",
        "    f'  --lr_classifier {LR_CLASSIFIER} \\\n",
        "'\n",
        "    f'  --weight_decay {WEIGHT_DECAY} \\\n",
        "'\n",
        "    f'  --num_workers {NUM_WORKERS} \\\n",
        "'\n",
        "    f'  {det_flag} \\\n",
        "'\n",
        "    f'  --seed {SEED}'\n",
        ").strip()\n",
        "\n",
        "print(\"Training command:\\n\", SRC_CMD)\n",
        "!{SRC_CMD}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc0d371b",
      "metadata": {
        "id": "dc0d371b"
      },
      "source": [
        "## 6. Run ME-IIS adaptation\n",
        "Uses the source checkpoint above plus the ME-IIS settings in the config cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70ccabb8",
      "metadata": {
        "id": "70ccabb8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "det_flag = \"--deterministic\" if DETERMINISTIC else \"\"\n",
        "os.chdir(REPO_DIR)\n",
        "\n",
        "ADAPT_CMD = (\n",
        "    'python scripts/adapt_me_iis.py \\\n",
        "'\n",
        "    f'  --dataset_name {DATASET_NAME} \\\n",
        "'\n",
        "    f'  --data_root \"{DATA_ROOT}\" \\\n",
        "'\n",
        "    f'  --source_domain {SOURCE_DOMAIN} \\\n",
        "'\n",
        "    f'  --target_domain {TARGET_DOMAIN} \\\n",
        "'\n",
        "    f'  --checkpoint {get_source_ckpt_path()} \\\n",
        "'\n",
        "    f'  --batch_size {BATCH_SIZE_SRC} \\\n",
        "'\n",
        "    f'  --num_workers {NUM_WORKERS} \\\n",
        "'\n",
        "    f'  --feature_layers \"{FEATURE_LAYERS}\" \\\n",
        "'\n",
        "    f'  --num_latent_styles {NUM_LATENT_STYLES} \\\n",
        "'\n",
        "    f'  --gmm_selection_mode {GMM_SELECTION_MODE} \\\n",
        "'\n",
        "    f'  --gmm_bic_min_components {GMM_BIC_MIN_COMPONENTS} \\\n",
        "'\n",
        "    f'  --gmm_bic_max_components {GMM_BIC_MAX_COMPONENTS} \\\n",
        "'\n",
        "    f'  --iis_iters {IIS_ITERS} \\\n",
        "'\n",
        "    f'  --iis_tol {IIS_TOL} \\\n",
        "'\n",
        "    f'  --adapt_epochs {ADAPT_EPOCHS} \\\n",
        "'\n",
        "    f'  {'--finetune_backbone' if FINETUNE_BACKBONE else ''} \\\n",
        "'\n",
        "    f'  --backbone_lr_scale {BACKBONE_LR_SCALE} \\\n",
        "'\n",
        "    f'  --classifier_lr {CLASSIFIER_LR} \\\n",
        "'\n",
        "    f'  --weight_decay {ADAPT_WEIGHT_DECAY} \\\n",
        "'\n",
        "    f'  --source_prob_mode {SOURCE_PROB_MODE} \\\n",
        "'\n",
        "    f'  {det_flag} \\\n",
        "'\n",
        "    f'  --seed {SEED}'\n",
        ").strip()\n",
        "\n",
        "if USE_PSEUDO_LABELS:\n",
        "    ADAPT_CMD += (\n",
        "        f\" --use_pseudo_labels --pseudo_conf_thresh {PSEUDO_CONF_THRESH} \"\n",
        "        f\"--pseudo_max_ratio {PSEUDO_MAX_RATIO} --pseudo_loss_weight {PSEUDO_LOSS_WEIGHT}\"\n",
        "    )\n",
        "\n",
        "if COMPONENTS_OVERRIDE.strip():\n",
        "    ADAPT_CMD += f' --components_per_layer \"{COMPONENTS_OVERRIDE}\"'\n",
        "\n",
        "print(\"Adaptation command:\\n\", ADAPT_CMD)\n",
        "!{ADAPT_CMD}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a40ccf29",
      "metadata": {
        "id": "a40ccf29"
      },
      "source": [
        "## 7. Optional: experiment driver examples\n",
        "Leave `RUN_EXPERIMENT_DRIVER = False` for the standard train + adapt path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec4236ee",
      "metadata": {
        "id": "ec4236ee"
      },
      "outputs": [],
      "source": [
        "RUN_EXPERIMENT_DRIVER = False\n",
        "\n",
        "if RUN_EXPERIMENT_DRIVER:\n",
        "    import os\n",
        "    os.chdir(REPO_DIR)\n",
        "    det_flag = \"--deterministic\" if DETERMINISTIC else \"\"\n",
        "    EXP_CMD = (\n",
        "        'python scripts/run_me_iis_experiments.py \\\n",
        "'\n",
        "        f'  --dataset_name {DATASET_NAME} \\\n",
        "'\n",
        "        f'  --source_domain {SOURCE_DOMAIN} \\\n",
        "'\n",
        "        f'  --target_domain {TARGET_DOMAIN} \\\n",
        "'\n",
        "        '  --experiment_family layers \\\n",
        "'\n",
        "        f'  --seeds {SEED} \\\n",
        "'\n",
        "        f'  --base_data_root \"{DATA_ROOT}\" \\\n",
        "'\n",
        "        f'  --feature_layers \"{FEATURE_LAYERS}\" \\\n",
        "'\n",
        "        f'  --num_latent_styles {NUM_LATENT_STYLES} \\\n",
        "'\n",
        "        f'  --gmm_selection_mode {GMM_SELECTION_MODE} \\\n",
        "'\n",
        "        f'  --gmm_bic_min_components {GMM_BIC_MIN_COMPONENTS} \\\n",
        "'\n",
        "        f'  --gmm_bic_max_components {GMM_BIC_MAX_COMPONENTS} \\\n",
        "'\n",
        "        f'  --source_prob_mode {SOURCE_PROB_MODE} \\\n",
        "'\n",
        "        f'  --num_epochs {NUM_EPOCHS_SRC} \\\n",
        "'\n",
        "        f'  --batch_size {BATCH_SIZE_SRC} \\\n",
        "'\n",
        "        f'  --num_workers {NUM_WORKERS} \\\n",
        "'\n",
        "        f'  --iis_iters {IIS_ITERS} \\\n",
        "'\n",
        "        f'  --iis_tol {IIS_TOL} \\\n",
        "'\n",
        "        f'  --adapt_epochs {ADAPT_EPOCHS} \\\n",
        "'\n",
        "        f'  --backbone_lr_scale {BACKBONE_LR_SCALE} \\\n",
        "'\n",
        "        f'  --classifier_lr {CLASSIFIER_LR} \\\n",
        "'\n",
        "        f'  --weight_decay {ADAPT_WEIGHT_DECAY} \\\n",
        "'\n",
        "        f'  {'--finetune_backbone' if FINETUNE_BACKBONE else ''} \\\n",
        "'\n",
        "        f'  {det_flag} \\\n",
        "'\n",
        "        f'  --output_csv results/me_iis_layers_{SOURCE_DOMAIN}_to_{TARGET_DOMAIN}_seed{SEED}.csv'\n",
        "    ).strip()\n",
        "\n",
        "    if COMPONENTS_OVERRIDE.strip():\n",
        "        EXP_CMD += f' --components_per_layer \"{COMPONENTS_OVERRIDE}\"'\n",
        "\n",
        "    if USE_PSEUDO_LABELS:\n",
        "        EXP_CMD += (\n",
        "            f\" --pseudo_conf_thresh {PSEUDO_CONF_THRESH} \"\n",
        "            f\"--pseudo_max_ratio {PSEUDO_MAX_RATIO} --pseudo_loss_weight {PSEUDO_LOSS_WEIGHT}\"\n",
        "        )\n",
        "\n",
        "    if det_flag:\n",
        "        EXP_CMD += f\" {det_flag}\"\n",
        "\n",
        "    print(\"Experiment driver command:\\n\", EXP_CMD)\n",
        "    !{EXP_CMD}\n",
        "else:\n",
        "    print(\"Experiment driver is disabled (set RUN_EXPERIMENT_DRIVER = True to run).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1eb1c47",
      "metadata": {
        "id": "c1eb1c47"
      },
      "source": [
        "## 8. Notes on outputs\n",
        "- Source checkpoints: `checkpoints/source_only_*` (auto-resume uses the matching file name).\n",
        "- ME-IIS checkpoints and IIS weights: `checkpoints/me_iis_*` and `results/me_iis_weights_*.npz`.\n",
        "- CSV log of source/adapt runs: `results/office_home_me_iis.csv` (dataset column distinguishes Office-Home vs Office-31).\n",
        "- Experiment driver summaries (optional): `results/me_iis_experiments_summary.csv` or the path you pass via `--output_csv`.\n",
        "- TensorBoard logs live under `runs/` (`runs/source_only` and `runs/adapt_me_iis`)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}