{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kaminglui/Domain-Adaptation-with-ME-IIS/blob/main/notebooks/Run_All_Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run All Experiments (Unified UDA Runner)\n",
    "\n",
    "Runs a clean baseline suite with a single shared runner:\n",
    "- `source_only`, `dann`, `dan`, `jan`, `cdan`, `me_iis` (optional `pseudo_label`)\n",
    "\n",
    "Each run writes artifacts to:\n",
    "`outputs/runs/{dataset}/{src}2{tgt}/{method}/{run_id}/`\n",
    "\n",
    "Every run saves `signature.json` (method routing guard), `metrics.csv`, logs, and checkpoints.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "# Optional: mount Drive (set MOUNT_DRIVE=1) and point ME_IIS_DATA_ROOT to a Drive path.\n",
    "if IN_COLAB and os.getenv(\"MOUNT_DRIVE\", \"0\") == \"1\":\n",
    "    try:\n",
    "        from google.colab import drive  # type: ignore\n",
    "\n",
    "        drive.mount(\"/content/drive\")\n",
    "    except Exception as exc:\n",
    "        print(\"[Drive][WARN]\", exc)\n",
    "\n",
    "REPO_URL = os.getenv(\n",
    "    \"ME_IIS_REPO_URL\",\n",
    "    \"https://github.com/kaminglui/Domain-Adaptation-with-ME-IIS.git\",\n",
    ")\n",
    "REPO_DIR = Path(\n",
    "    os.getenv(\n",
    "        \"ME_IIS_REPO_DIR\",\n",
    "        \"/content/Domain-Adaptation-with-ME-IIS\" if IN_COLAB else str(Path.cwd()),\n",
    "    )\n",
    ").expanduser()\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not (REPO_DIR / \".git\").exists():\n",
    "        subprocess.run([\"git\", \"clone\", \"--depth\", \"1\", REPO_URL, str(REPO_DIR)], check=True)\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"-q\", \"install\", \"-r\", str(REPO_DIR / \"requirements.txt\")], check=True)\n",
    "    os.chdir(REPO_DIR)\n",
    "\n",
    "REPO_ROOT = Path.cwd().resolve()\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "print(\"Repo root:\", REPO_ROOT)\n",
    "try:\n",
    "    sha = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"], cwd=REPO_ROOT).decode().strip()\n",
    "    print(\"git sha:\", sha)\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- Single config cell ----------------\n",
    "DATASET = os.getenv(\"ME_IIS_DATASET\", \"office_home\")  # office_home | office31\n",
    "DATA_ROOT = os.getenv(\"ME_IIS_DATA_ROOT\", \"\")         # set this if not using repo-local datasets/\n",
    "MODE = os.getenv(\"ME_IIS_MODE\", \"quick\")              # quick | full\n",
    "\n",
    "INCLUDE_PSEUDO = os.getenv(\"ME_IIS_INCLUDE_PSEUDO\", \"0\") == \"1\"\n",
    "METHODS = [\"source_only\", \"dann\", \"dan\", \"jan\", \"cdan\", \"me_iis\"]\n",
    "if INCLUDE_PSEUDO:\n",
    "    METHODS.append(\"pseudo_label\")\n",
    "\n",
    "SEEDS = [0] if MODE == \"quick\" else [0, 1, 2]\n",
    "\n",
    "name = DATASET.lower().replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "if name == \"officehome\":\n",
    "    DOMAINS = [\"Ar\", \"Cl\", \"Pr\", \"Rw\"]\n",
    "elif name == \"office31\":\n",
    "    DOMAINS = [\"A\", \"D\", \"W\"]\n",
    "else:\n",
    "    raise ValueError(f\"Unknown dataset '{DATASET}'\")\n",
    "\n",
    "if MODE == \"quick\":\n",
    "    DOMAIN_PAIRS = [(\"Ar\", \"Cl\")] if DOMAINS == [\"Ar\", \"Cl\", \"Pr\", \"Rw\"] else [(\"A\", \"W\")]\n",
    "else:\n",
    "    DOMAIN_PAIRS = [(s, t) for s in DOMAINS for t in DOMAINS if s != t]\n",
    "\n",
    "FORCE_RERUN = os.getenv(\"ME_IIS_FORCE_RERUN\", \"0\") == \"1\"\n",
    "DEVICE = os.getenv(\"ME_IIS_DEVICE\", \"cuda\")  # cuda | cpu | cuda:0\n",
    "AMP = None  # None=default, True/False override\n",
    "\n",
    "FREEZE_BACKBONE = os.getenv(\"ME_IIS_FREEZE_BACKBONE\", \"0\") == \"1\"\n",
    "BOTTLENECK_DIM = int(os.getenv(\"ME_IIS_BOTTLENECK_DIM\", \"256\"))\n",
    "\n",
    "EPOCHS_SOURCE = 1 if MODE == \"quick\" else 50\n",
    "EPOCHS_ADAPT = 1 if MODE == \"quick\" else 10\n",
    "BATCH_SIZE = 8 if MODE == \"quick\" else 32\n",
    "NUM_WORKERS = 0 if MODE == \"quick\" else 4\n",
    "\n",
    "DRY_RUN_MAX_SAMPLES = 256 if MODE == \"quick\" else 0\n",
    "DRY_RUN_MAX_BATCHES = 0  # set >0 to cap optimizer steps for debugging\n",
    "\n",
    "# Colab-first defaults: enable auto resource tuning and set device for all runs.\n",
    "os.environ[\"ME_IIS_DEVICE\"] = str(DEVICE)\n",
    "if os.environ.get(\"ME_IIS_AUTO_RESOURCES\") is None:\n",
    "    os.environ[\"ME_IIS_AUTO_RESOURCES\"] = \"1\" if (\"google.colab\" in sys.modules) else \"0\"\n",
    "\n",
    "# Resolve dataset root and optionally cache Drive -> local SSD on Colab.\n",
    "if not DATA_ROOT:\n",
    "    if name == \"officehome\":\n",
    "        DATA_ROOT = str(Path(\"datasets\") / \"Office-Home\")\n",
    "    elif name == \"office31\":\n",
    "        DATA_ROOT = str(Path(\"datasets\") / \"Office-31\")\n",
    "\n",
    "from utils.resource_auto import maybe_cache_dataset_to_local\n",
    "\n",
    "resolved_root, cache_info = maybe_cache_dataset_to_local(dataset_name=DATASET, data_root=Path(DATA_ROOT))\n",
    "DATA_ROOT = str(resolved_root)\n",
    "\n",
    "print(\"DATASET:\", DATASET)\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"MODE:\", MODE, \"| seeds:\", SEEDS, \"| methods:\", METHODS, \"| pairs:\", len(DOMAIN_PAIRS))\n",
    "print(\"CACHE:\", cache_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.resource_auto import detect_resources\n",
    "from src.experiments.run_config import default_runs_root\n",
    "\n",
    "runs_root = default_runs_root()\n",
    "snap = detect_resources(disk_path=runs_root, data_path=Path(DATA_ROOT), cuda_device=0)\n",
    "print(json.dumps(snap.to_json_dict(), indent=2, sort_keys=True))\n",
    "print(\"runs_root:\", runs_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from src.experiments.run_config import RunConfig, get_run_dir\n",
    "from src.experiments.runner import run_one\n",
    "\n",
    "# Override to place runs elsewhere (default is Colab-local SSD when available).\n",
    "RUNS_ROOT = None\n",
    "\n",
    "\n",
    "def make_cfg(method: str, src: str, tgt: str, seed: int) -> RunConfig:\n",
    "    method_params = {}\n",
    "    if AMP is not None:\n",
    "        method_params[\"amp\"] = bool(AMP)\n",
    "    if method == \"me_iis\":\n",
    "        method_params.update(\n",
    "            {\n",
    "                \"feature_layers\": [\"layer3\", \"layer4\"],\n",
    "                \"iis_iters\": 15 if MODE != \"quick\" else 5,\n",
    "                \"gmm_selection_mode\": \"fixed\",\n",
    "                \"num_latent_styles\": 5,\n",
    "                \"cluster_clean_ratio\": 1.0,\n",
    "            }\n",
    "        )\n",
    "    if method == \"pseudo_label\":\n",
    "        method_params.update(\n",
    "            {\n",
    "                \"pseudo_conf_thresh\": 0.9,\n",
    "                \"pseudo_max_ratio\": 1.0,\n",
    "                \"pseudo_loss_weight\": 1.0,\n",
    "            }\n",
    "        )\n",
    "    epochs_adapt = 0 if method == \"source_only\" else int(EPOCHS_ADAPT)\n",
    "    return RunConfig(\n",
    "        dataset_name=str(DATASET),\n",
    "        data_root=str(DATA_ROOT),\n",
    "        source_domain=str(src),\n",
    "        target_domain=str(tgt),\n",
    "        method=str(method),\n",
    "        epochs_source=int(EPOCHS_SOURCE),\n",
    "        epochs_adapt=int(epochs_adapt),\n",
    "        batch_size=int(BATCH_SIZE),\n",
    "        num_workers=int(NUM_WORKERS),\n",
    "        bottleneck_dim=int(BOTTLENECK_DIM),\n",
    "        finetune_backbone=bool(not FREEZE_BACKBONE),\n",
    "        method_params=method_params,\n",
    "        seed=int(seed),\n",
    "        deterministic=True,\n",
    "        dry_run_max_samples=int(DRY_RUN_MAX_SAMPLES),\n",
    "        dry_run_max_batches=int(DRY_RUN_MAX_BATCHES),\n",
    "    )\n",
    "\n",
    "\n",
    "configs = []\n",
    "results = []\n",
    "\n",
    "for (src, tgt) in DOMAIN_PAIRS:\n",
    "    for seed in SEEDS:\n",
    "        for method in METHODS:\n",
    "            cfg = make_cfg(method, src, tgt, seed)\n",
    "            configs.append(cfg)\n",
    "            run_dir = get_run_dir(cfg, runs_root=RUNS_ROOT)\n",
    "            print(f\"[RUN] {method} {src}->{tgt} seed={seed} run_id={cfg.run_id} dir={run_dir}\")\n",
    "            t0 = time.time()\n",
    "            res = run_one(\n",
    "                cfg,\n",
    "                force_rerun=bool(FORCE_RERUN),\n",
    "                runs_root=RUNS_ROOT,\n",
    "                write_metrics=True,\n",
    "                raise_on_error=False,\n",
    "            )\n",
    "            res = dict(res)\n",
    "            res[\"elapsed_sec\"] = round(time.time() - t0, 3)\n",
    "            results.append(res)\n",
    "            status = res.get(\"status\")\n",
    "            extra = res.get(\"error\") or \"\"\n",
    "            print(f\"  status={status} elapsed={res['elapsed_sec']}s {extra}\")\n",
    "\n",
    "print(\"Total runs:\", len(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from src.experiments.notebook_summary import collect_expected_runs\n",
    "\n",
    "rows = collect_expected_runs(configs, runs_root=RUNS_ROOT)\n",
    "\n",
    "try:\n",
    "    import pandas as pd  # type: ignore\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    display(df[\"status\"].value_counts())\n",
    "    display(df[[\"dataset\", \"src\", \"tgt\", \"method\", \"seed\", \"status\", \"target_acc\", \"run_dir\"]])\n",
    "\n",
    "    ok = df[df[\"status\"] == \"OK\"].copy()\n",
    "    ok[\"target_acc\"] = ok[\"target_acc\"].astype(float)\n",
    "\n",
    "    # Per-task table (index: transfer+seed, columns: method)\n",
    "    pivot = ok.pivot_table(index=[\"src\", \"tgt\", \"seed\"], columns=\"method\", values=\"target_acc\")\n",
    "    display(pivot)\n",
    "\n",
    "    # Paper-style: 12-transfer average per seed, then meanÂ±std across seeds.\n",
    "    per_seed = ok.groupby([\"method\", \"seed\"])[\"target_acc\"].mean().reset_index()\n",
    "    summary = per_seed.groupby(\"method\")[\"target_acc\"].agg([\"mean\", \"std\", \"count\"]).reset_index()\n",
    "    summary = summary.rename(columns={\"mean\": \"mean_12transfer\", \"std\": \"std_across_seeds\", \"count\": \"num_seeds\"})\n",
    "    display(summary.sort_values(\"mean_12transfer\", ascending=False))\n",
    "\n",
    "    bad = df[df.get(\"invalid_comparison\", False) == True]\n",
    "    if len(bad):\n",
    "        display(bad[[\"dataset\", \"src\", \"tgt\", \"seed\", \"method\", \"signature_fingerprint\", \"invalid_with_methods\"]])\n",
    "except Exception as exc:\n",
    "    print(\"[WARN] pandas summary unavailable:\", exc)\n",
    "    ok = [r for r in rows if r.get(\"status\") == \"OK\" and str(r.get(\"target_acc\", \"\")).strip()]\n",
    "    by_method_seed = defaultdict(list)\n",
    "    for r in ok:\n",
    "        by_method_seed[(r[\"method\"], int(r[\"seed\"]))].append(float(r[\"target_acc\"]))\n",
    "\n",
    "    import statistics\n",
    "\n",
    "    out = []\n",
    "    for method in METHODS:\n",
    "        seed_means = []\n",
    "        for seed in SEEDS:\n",
    "            vals = by_method_seed.get((method, seed), [])\n",
    "            if vals:\n",
    "                seed_means.append(sum(vals) / len(vals))\n",
    "        if seed_means:\n",
    "            out.append(\n",
    "                {\n",
    "                    \"method\": method,\n",
    "                    \"mean_12transfer\": sum(seed_means) / len(seed_means),\n",
    "                    \"std_across_seeds\": statistics.pstdev(seed_means) if len(seed_means) > 1 else 0.0,\n",
    "                    \"num_seeds\": len(seed_means),\n",
    "                }\n",
    "            )\n",
    "    for row in sorted(out, key=lambda x: x[\"mean_12transfer\"], reverse=True):\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from src.experiments.run_config import get_run_dir\n",
    "\n",
    "samples = {}\n",
    "for cfg in configs:\n",
    "    run_dir = Path(get_run_dir(cfg, runs_root=RUNS_ROOT))\n",
    "    sig_path = run_dir / \"signature.json\"\n",
    "    if not sig_path.exists():\n",
    "        continue\n",
    "    sig = json.loads(sig_path.read_text(encoding=\"utf-8\"))\n",
    "    method = sig.get(\"method_name\", cfg.method)\n",
    "    if method in samples:\n",
    "        continue\n",
    "    samples[method] = {\n",
    "        \"amp\": sig.get(\"method_params_used\", {}).get(\"amp\"),\n",
    "        \"dataloader\": sig.get(\"dataloader\"),\n",
    "        \"step_budget\": sig.get(\"step_budget\"),\n",
    "        \"comparison_fingerprint\": sig.get(\"comparison_fingerprint\"),\n",
    "    }\n",
    "\n",
    "samples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

