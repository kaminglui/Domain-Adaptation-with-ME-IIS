{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run All UDA Experiments (ME-IIS + Fair Baselines)\n",
        "\n",
        "This notebook runs **source-only**, **ME-IIS**, and fair UDA baselines (**DANN**, **CORAL**, optional **pseudo-label self-training**) with:\n",
        "- deterministic `run_id` + run directories under `outputs/runs/...`\n",
        "- **skip/resume** (no redundant retraining)\n",
        "- unified evaluation + `metrics.csv` per run\n",
        "- QUICK mode (seed=[0]) and FULL mode (seed list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup (clone + install)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "REPO_URL = \"https://github.com/kaminglui/ME-IIS.git\"\n",
        "REPO_DIR = Path(os.getenv(\"REPO_DIR\", \"/content/ME-IIS\" if IN_COLAB else Path.cwd())).expanduser()\n",
        "PULL_LATEST = True\n",
        "\n",
        "if IN_COLAB:\n",
        "    try:\n",
        "        from google.colab import drive  # type: ignore\n",
        "        if os.getenv(\"MOUNT_DRIVE\", \"0\") == \"1\":\n",
        "            drive.mount(\"/content/drive\")\n",
        "    except Exception as exc:\n",
        "        print(\"[Drive] Skipping Drive mount:\", exc)\n",
        "\n",
        "if not REPO_DIR.exists():\n",
        "    REPO_DIR.parent.mkdir(parents=True, exist_ok=True)\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL, str(REPO_DIR)], check=True)\n",
        "else:\n",
        "    print(f\"[Repo] Using existing repo at {REPO_DIR}\")\n",
        "    if PULL_LATEST:\n",
        "        try:\n",
        "            subprocess.run([\"git\", \"pull\", \"--ff-only\"], cwd=REPO_DIR, check=True)\n",
        "        except subprocess.CalledProcessError as exc:\n",
        "            print(\"[Repo][WARN] git pull failed (keeping existing checkout):\", exc)\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"[Repo] CWD:\", Path.cwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, subprocess\n",
        "\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"], check=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Config (single cell)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Dataset (single place to edit)\n",
        "DATASET_NAME = \"office_home\"  # office_home | office31\n",
        "DATA_ROOT = \"\"  # optional path; leave blank to auto-download\n",
        "\n",
        "# Optional: override via env vars (Colab-friendly)\n",
        "DATASET_NAME = os.getenv(\"DATASET_NAME\", DATASET_NAME)\n",
        "DATA_ROOT = os.getenv(\"DATA_ROOT\", DATA_ROOT)\n",
        "\n",
        "# Mode\n",
        "MODE = \"QUICK\"  # QUICK | FULL\n",
        "FORCE_RERUN = False\n",
        "\n",
        "# Task\n",
        "SOURCE_DOMAIN = \"Ar\"  # Office-Home: Ar/Cl/Pr/Rw ; Office-31: A/D/W\n",
        "TARGET_DOMAIN = \"Cl\"\n",
        "\n",
        "# Seeds\n",
        "SEEDS = [0] if MODE == \"QUICK\" else [0, 1, 2]\n",
        "DETERMINISTIC = True\n",
        "\n",
        "# Training budget (fair across methods)\n",
        "EPOCHS_SOURCE = 2 if MODE == \"QUICK\" else 50\n",
        "EPOCHS_ADAPT = 2 if MODE == \"QUICK\" else 10\n",
        "BATCH_SIZE = 16 if MODE == \"QUICK\" else 32\n",
        "NUM_WORKERS = 2 if MODE == \"QUICK\" else 4\n",
        "\n",
        "# Optimizer schedule\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 1e-3\n",
        "LR_BACKBONE = 1e-3\n",
        "LR_CLASSIFIER = 1e-2\n",
        "\n",
        "# Adaptation optimizer schedule (shared)\n",
        "FINETUNE_BACKBONE = False\n",
        "BACKBONE_LR_SCALE = 0.1\n",
        "CLASSIFIER_LR_ADAPT = 1e-2\n",
        "\n",
        "# Optional speed limits (keep 0 for real runs)\n",
        "DRY_RUN_MAX_SAMPLES = 0\n",
        "DRY_RUN_MAX_BATCHES = 0\n",
        "\n",
        "# Where to store outputs. If you mounted Drive, you may want a Drive path here.\n",
        "RUNS_ROOT = Path(\"outputs\") / \"runs\"\n",
        "\n",
        "# ME-IIS params\n",
        "ME_IIS_PARAMS = {\n",
        "    \"feature_layers\": [\"layer3\", \"layer4\"],\n",
        "    \"num_latent_styles\": 5,\n",
        "    \"components_per_layer\": None,\n",
        "    \"cluster_backend\": \"gmm\",  # gmm | vmf_softmax\n",
        "    \"gmm_selection_mode\": \"fixed\",  # fixed | bic\n",
        "    \"gmm_bic_min_components\": 2,\n",
        "    \"gmm_bic_max_components\": 8,\n",
        "    \"vmf_kappa\": 20.0,\n",
        "    \"cluster_clean_ratio\": 1.0,\n",
        "    \"kmeans_n_init\": 10,\n",
        "    \"source_prob_mode\": \"softmax\",  # softmax | onehot\n",
        "    \"iis_iters\": 5 if MODE == \"QUICK\" else 15,\n",
        "    \"iis_tol\": 1e-3,\n",
        "    \"use_pseudo_labels\": False,\n",
        "    \"pseudo_conf_thresh\": 0.9,\n",
        "    \"pseudo_max_ratio\": 1.0,\n",
        "    \"pseudo_loss_weight\": 1.0,\n",
        "}\n",
        "\n",
        "# DANN params\n",
        "DANN_PARAMS = {\n",
        "    \"disc_hidden_dim\": 1024,\n",
        "    \"disc_dropout\": 0.0,\n",
        "    \"dann_lambda_schedule\": \"grl\",  # grl | linear | constant\n",
        "    \"domain_loss_weight\": 1.0,\n",
        "}\n",
        "\n",
        "# CORAL params\n",
        "CORAL_PARAMS = {\n",
        "    \"feature_layers\": [\"layer3\", \"layer4\"],\n",
        "    \"coral_weight\": 1.0,\n",
        "}\n",
        "\n",
        "# Pseudo-label baseline params\n",
        "PL_PARAMS = {\n",
        "    \"pseudo_conf_thresh\": 0.9,\n",
        "    \"pseudo_max_ratio\": 1.0,\n",
        "    \"pseudo_loss_weight\": 1.0,\n",
        "}\n",
        "\n",
        "print(\"[CFG] MODE:\", MODE)\n",
        "print(\"[CFG] DATASET_NAME:\", DATASET_NAME)\n",
        "print(\"[CFG] DATA_ROOT:\", DATA_ROOT)\n",
        "print(\"[CFG] TASK:\", f\"{SOURCE_DOMAIN} -> {TARGET_DOMAIN}\")\n",
        "print(\"[CFG] SEEDS:\", SEEDS)\n",
        "print(\"[CFG] RUNS_ROOT:\", RUNS_ROOT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Data (download/verify)\n",
        "\n",
        "Supports `office_home` and `office31`.\n",
        "- Leave `DATA_ROOT` blank to auto-download (KaggleHub).\n",
        "- If you already have the dataset (or in Drive), set `DATA_ROOT` in the config cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def _find_office_home_root(base: Path) -> Path:\n",
        "    real_candidates = [\"RealWorld\", \"Real World\", \"Real_World\", \"Real\"]\n",
        "    candidates = [base] + [p for p in base.rglob(\"*\") if p.is_dir()]\n",
        "    for cand in candidates:\n",
        "        if all((cand / sub).exists() for sub in [\"Art\", \"Clipart\", \"Product\"]) and any((cand / r).exists() for r in real_candidates):\n",
        "            return cand\n",
        "    return base\n",
        "\n",
        "\n",
        "def _find_office31_root(base: Path) -> Path:\n",
        "    candidates = [base] + [p for p in base.rglob(\"*\") if p.is_dir()]\n",
        "    for cand in candidates:\n",
        "        names = {p.name.lower() for p in cand.iterdir() if p.is_dir()}\n",
        "        if {\"amazon\", \"dslr\", \"webcam\"} <= names:\n",
        "            return cand\n",
        "    return base\n",
        "\n",
        "\n",
        "def _download_via_kagglehub(dataset_name: str) -> Path:\n",
        "    try:\n",
        "        import kagglehub  # type: ignore\n",
        "    except ImportError:\n",
        "        import sys, subprocess\n",
        "\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"kagglehub\"], check=True)\n",
        "        import kagglehub  # type: ignore\n",
        "\n",
        "    if dataset_name == \"office_home\":\n",
        "        raw = Path(kagglehub.dataset_download(\"lhrrraname/officehome\"))\n",
        "        return _find_office_home_root(raw)\n",
        "    if dataset_name == \"office31\":\n",
        "        raw = Path(kagglehub.dataset_download(\"xixuhu/office31\"))\n",
        "        return _find_office31_root(raw)\n",
        "    raise ValueError(f\"Unknown DATASET_NAME={dataset_name}\")\n",
        "\n",
        "\n",
        "data_root_str = str(DATA_ROOT).strip()\n",
        "data_root_path = Path(data_root_str).expanduser() if data_root_str else None\n",
        "\n",
        "if data_root_path is None:\n",
        "    print(\"[Data] DATA_ROOT not set; downloading via KaggleHub...\")\n",
        "    data_root_path = _download_via_kagglehub(DATASET_NAME)\n",
        "else:\n",
        "    # Be forgiving if the user points to a parent directory.\n",
        "    if DATASET_NAME == \"office_home\":\n",
        "        expected = [\"Art\", \"Clipart\", \"Product\"]\n",
        "        if not all((data_root_path / sub).exists() for sub in expected):\n",
        "            data_root_path = _find_office_home_root(data_root_path)\n",
        "    elif DATASET_NAME == \"office31\":\n",
        "        expected = [\"amazon\", \"dslr\", \"webcam\"]\n",
        "        names = {p.name.lower() for p in data_root_path.iterdir() if p.is_dir()} if data_root_path.exists() else set()\n",
        "        if not set(expected) <= names:\n",
        "            data_root_path = _find_office31_root(data_root_path)\n",
        "\n",
        "DATA_ROOT = Path(data_root_path).resolve()\n",
        "print(\"[Data] DATASET_NAME:\", DATASET_NAME)\n",
        "print(\"[Data] DATA_ROOT:\", DATA_ROOT)\n",
        "print(\"[Data] Exists:\", DATA_ROOT.exists())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Run source-only (skip/resume)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.experiments.run_config import RunConfig\n",
        "from src.experiments.runner import run_one\n",
        "\n",
        "def make_cfg(method: str, seed: int, method_params: dict | None = None) -> RunConfig:\n",
        "    return RunConfig(\n",
        "        dataset_name=DATASET_NAME,\n",
        "        data_root=str(DATA_ROOT),\n",
        "        source_domain=SOURCE_DOMAIN,\n",
        "        target_domain=TARGET_DOMAIN,\n",
        "        method=method,\n",
        "        epochs_source=EPOCHS_SOURCE,\n",
        "        epochs_adapt=0 if method == \"source_only\" else EPOCHS_ADAPT,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        momentum=MOMENTUM,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        lr_backbone=LR_BACKBONE,\n",
        "        lr_classifier=LR_CLASSIFIER,\n",
        "        finetune_backbone=False if method == \"source_only\" else FINETUNE_BACKBONE,\n",
        "        backbone_lr_scale=0.1 if method == \"source_only\" else BACKBONE_LR_SCALE,\n",
        "        classifier_lr=1e-2 if method == \"source_only\" else CLASSIFIER_LR_ADAPT,\n",
        "        seed=seed,\n",
        "        deterministic=DETERMINISTIC,\n",
        "        dry_run_max_samples=DRY_RUN_MAX_SAMPLES,\n",
        "        dry_run_max_batches=DRY_RUN_MAX_BATCHES,\n",
        "        method_params={} if method == \"source_only\" else (method_params or {}),\n",
        "    )\n",
        "\n",
        "# Fairness guard: approximate optimizer-step budgets (epochs × batches)\n",
        "from src.experiments.budget import estimate_total_steps\n",
        "import pandas as pd\n",
        "\n",
        "budget_seed = SEEDS[0]\n",
        "budget_rows = []\n",
        "for method, params in [\n",
        "    (\"source_only\", {}),\n",
        "    (\"me_iis\", ME_IIS_PARAMS),\n",
        "    (\"dann\", DANN_PARAMS),\n",
        "    (\"coral\", CORAL_PARAMS),\n",
        "    (\"pseudo_label\", PL_PARAMS),\n",
        "]:\n",
        "    cfg_b = make_cfg(method, budget_seed, method_params=params)\n",
        "    budget_rows.append({\"method\": method, \"seed\": budget_seed, **estimate_total_steps(cfg_b)})\n",
        "display(pd.DataFrame(budget_rows))\n",
        "\n",
        "source_runs = []\n",
        "for seed in SEEDS:\n",
        "    cfg = make_cfg(\"source_only\", seed)\n",
        "    res = run_one(cfg, force_rerun=FORCE_RERUN, runs_root=RUNS_ROOT)\n",
        "    print(f\"[source_only][seed={seed}] status={res['status']} src_acc={res.get('source_acc_eval')} tgt_acc={res.get('target_acc_eval')} run_dir={res['run_dir']} ckpt={res.get('checkpoint')} metrics={res.get('metrics_csv')}\")\n",
        "    source_runs.append(res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Run adaptation (ME-IIS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "me_iis_runs = []\n",
        "for seed in SEEDS:\n",
        "    cfg = make_cfg(\"me_iis\", seed, method_params=ME_IIS_PARAMS)\n",
        "    res = run_one(cfg, force_rerun=FORCE_RERUN, runs_root=RUNS_ROOT)\n",
        "    print(f\"[me_iis][seed={seed}] status={res['status']} src_acc={res.get('source_acc_eval')} tgt_acc={res.get('target_acc_eval')} run_dir={res['run_dir']} ckpt={res.get('checkpoint')} metrics={res.get('metrics_csv')}\")\n",
        "    me_iis_runs.append(res)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Run baselines (DANN / CORAL / pseudo-label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_runs = []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    cfg = make_cfg(\"dann\", seed, method_params=DANN_PARAMS)\n",
        "    res = run_one(cfg, force_rerun=FORCE_RERUN, runs_root=RUNS_ROOT)\n",
        "    print(f\"[dann][seed={seed}] status={res['status']} src_acc={res.get('source_acc_eval')} tgt_acc={res.get('target_acc_eval')} run_dir={res['run_dir']} ckpt={res.get('checkpoint')} metrics={res.get('metrics_csv')}\")\n",
        "    baseline_runs.append(res)\n",
        "\n",
        "for seed in SEEDS:\n",
        "    cfg = make_cfg(\"coral\", seed, method_params=CORAL_PARAMS)\n",
        "    res = run_one(cfg, force_rerun=FORCE_RERUN, runs_root=RUNS_ROOT)\n",
        "    print(f\"[coral][seed={seed}] status={res['status']} src_acc={res.get('source_acc_eval')} tgt_acc={res.get('target_acc_eval')} run_dir={res['run_dir']} ckpt={res.get('checkpoint')} metrics={res.get('metrics_csv')}\")\n",
        "    baseline_runs.append(res)\n",
        "\n",
        "for seed in SEEDS:\n",
        "    cfg = make_cfg(\"pseudo_label\", seed, method_params=PL_PARAMS)\n",
        "    res = run_one(cfg, force_rerun=FORCE_RERUN, runs_root=RUNS_ROOT)\n",
        "    print(f\"[pseudo_label][seed={seed}] status={res['status']} src_acc={res.get('source_acc_eval')} tgt_acc={res.get('target_acc_eval')} run_dir={res['run_dir']} ckpt={res.get('checkpoint')} metrics={res.get('metrics_csv')}\")\n",
        "    baseline_runs.append(res)\n",
        "\n",
        "print(\"[Logs] Each run writes logs to: <run_dir>/logs/stdout.txt and <run_dir>/logs/stderr.txt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Summaries (tables + plots)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from utils.experiment_utils import dataset_tag\n",
        "\n",
        "ds_tag = dataset_tag(DATASET_NAME)\n",
        "pair = f\"{SOURCE_DOMAIN}2{TARGET_DOMAIN}\"\n",
        "metrics_glob = RUNS_ROOT / ds_tag / pair\n",
        "metrics_files = list(metrics_glob.glob(\"*/*/metrics.csv\"))\n",
        "print(f\"[Summary] Found {len(metrics_files)} metrics.csv files under {metrics_glob}\")\n",
        "\n",
        "if not metrics_files:\n",
        "    print(\"No runs found yet.\")\n",
        "else:\n",
        "    df = pd.concat([pd.read_csv(p) for p in metrics_files], ignore_index=True)\n",
        "    df = df.sort_values([\"method\", \"seed\"]).reset_index(drop=True)\n",
        "    display(df[[\"method\", \"seed\", \"source_acc\", \"target_acc\", \"run_id\", \"timestamp\"]])\n",
        "\n",
        "    pivot = df.pivot_table(index=\"method\", columns=\"seed\", values=\"target_acc\", aggfunc=\"first\")\n",
        "    pivot_display = pivot.copy().astype(object).where(~pivot.isna(), \"not run\")\n",
        "    print(\"Target accuracy by method x seed:\")\n",
        "    display(pivot_display)\n",
        "\n",
        "    stats = df.groupby(\"method\")[\"target_acc\"].agg([\"mean\", \"std\", \"count\"]).reset_index()\n",
        "    stats = stats.sort_values(\"mean\", ascending=False)\n",
        "    print(\"Mean ± std (target_acc):\")\n",
        "    display(stats)\n",
        "\n",
        "    # Bar chart (mean ± std)\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar(stats[\"method\"], stats[\"mean\"], yerr=stats[\"std\"].fillna(0), capsize=4)\n",
        "    plt.ylabel(\"Target Acc (%)\")\n",
        "    plt.title(f\"{DATASET_NAME} {SOURCE_DOMAIN}→{TARGET_DOMAIN} (mean±std over seeds)\")\n",
        "    plt.xticks(rotation=30, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Export artifacts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from utils.experiment_utils import dataset_tag\n",
        "\n",
        "ds_tag = dataset_tag(DATASET_NAME)\n",
        "pair = f\"{SOURCE_DOMAIN}2{TARGET_DOMAIN}\"\n",
        "out_dir = RUNS_ROOT / ds_tag / pair\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "metrics_files = list(out_dir.glob(\"*/*/metrics.csv\"))\n",
        "if not metrics_files:\n",
        "    print(\"No metrics to export.\")\n",
        "else:\n",
        "    df = pd.concat([pd.read_csv(p) for p in metrics_files], ignore_index=True)\n",
        "    export_path = out_dir / \"all_metrics.csv\"\n",
        "    df.to_csv(export_path, index=False)\n",
        "    print(\"[Export] Wrote:\", export_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
