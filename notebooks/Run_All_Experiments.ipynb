{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmck9VtljCnF"
      },
      "source": [
        "# Run All UDA Experiments (ME-IIS + Fair Baselines)\n",
        "\n",
        "This notebook runs **source-only**, **ME-IIS**, and fair UDA baselines (**DANN**, **CORAL**, optional **pseudo-label self-training**) with:\n",
        "- deterministic `run_id` + run directories under `outputs/runs/...`\n",
        "- **skip/resume** (no redundant retraining)\n",
        "- unified evaluation + `metrics.csv` per run\n",
        "- QUICK mode (seed=[0]) and FULL mode (seed list)\n"
      ],
      "id": "Pmck9VtljCnF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToHrY5IQjCnH"
      },
      "source": [
        "## 1) Setup (clone + install)\n"
      ],
      "id": "ToHrY5IQjCnH"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hC9PCjvejCnH",
        "outputId": "58ec21eb-e203-4b77-f298-53ae76c2feb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Repo] Using existing repo at /content/ME-IIS\n",
            "[Repo] CWD: /content/ME-IIS\n",
            "[Repo] HEAD: b08dd6a940c80cf55bdca1b1ad2f70c221ad65b6\n"
          ]
        }
      ],
      "source": [
        "import os, sys, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "REPO_URL = os.getenv(\"REPO_URL\", \"https://github.com/kaminglui/ME-IIS.git\")\n",
        "REPO_DIR = Path(os.getenv(\"REPO_DIR\", \"/content/ME-IIS\" if IN_COLAB else Path.cwd())).expanduser()\n",
        "PULL_LATEST = True\n",
        "\n",
        "if IN_COLAB:\n",
        "    try:\n",
        "        from google.colab import drive  # type: ignore\n",
        "        if os.getenv(\"MOUNT_DRIVE\", \"0\") == \"1\":\n",
        "            drive.mount(\"/content/drive\")\n",
        "    except Exception as exc:\n",
        "        print(\"[Drive] Skipping Drive mount:\", exc)\n",
        "\n",
        "if not REPO_DIR.exists():\n",
        "    REPO_DIR.parent.mkdir(parents=True, exist_ok=True)\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL, str(REPO_DIR)], check=True)\n",
        "else:\n",
        "    print(f\"[Repo] Using existing repo at {REPO_DIR}\")\n",
        "    if PULL_LATEST:\n",
        "        try:\n",
        "            subprocess.run([\"git\", \"pull\", \"--ff-only\"], cwd=REPO_DIR, check=True)\n",
        "        except subprocess.CalledProcessError as exc:\n",
        "            print(\"[Repo][WARN] git pull failed (keeping existing checkout):\", exc)\n",
        "\n",
        "os.chdir(REPO_DIR)\n",
        "print(\"[Repo] CWD:\", Path.cwd())\n",
        "try:\n",
        "    sha = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]).decode().strip()\n",
        "    print(\"[Repo] HEAD:\", sha)\n",
        "except Exception as exc:\n",
        "    print(\"[Repo][WARN] Could not read git sha:\", exc)\n"
      ],
      "id": "hC9PCjvejCnH"
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "if not IN_COLAB:\n",
        "    print(\"[Drive] Not in Colab; skipping Drive mount.\")\n",
        "else:\n",
        "    from google.colab import drive  # type: ignore\n",
        "\n",
        "    mount_point = Path(\"/content/drive\")\n",
        "    drive.mount(str(mount_point))\n",
        "\n",
        "    drive_root = mount_point / \"MyDrive\"\n",
        "    if not drive_root.exists():\n",
        "        raise RuntimeError(\"[Drive][ERROR] Mount completed but /content/drive/MyDrive is missing.\")\n",
        "\n",
        "    probe_dir = drive_root / \"ME-IIS\"\n",
        "    probe_dir.mkdir(parents=True, exist_ok=True)\n",
        "    probe_path = probe_dir / \"_drive_probe.txt\"\n",
        "    probe_path.write_text(\"ok\\n\", encoding=\"utf-8\")\n",
        "    if probe_path.read_text(encoding=\"utf-8\").strip() != \"ok\":\n",
        "        raise RuntimeError(\"[Drive][ERROR] Drive probe file readback failed.\")\n",
        "    print(\"[Drive] OK:\", probe_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6-jmCFVG6if",
        "outputId": "7c965ce9-e767-46d4-dd29-50c5ef0d27fb"
      },
      "id": "d6-jmCFVG6if",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H0NAn0NOjCnI",
        "outputId": "140ecf2a-6845-43b6-e276-184eda7ad7a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['/usr/bin/python3', '-m', 'pip', 'install', '-r', 'requirements.txt'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import sys, subprocess\n",
        "\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"], check=True)\n"
      ],
      "id": "H0NAn0NOjCnI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WhrQWWFjCnJ"
      },
      "source": [
        "## 2) Config (single cell)\n"
      ],
      "id": "0WhrQWWFjCnJ"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "esimj68EjCnJ",
        "outputId": "412c7272-a69e-4fc9-9714-9a84fb4ccd02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CFG] MODE: FULL\n",
            "[CFG] DATASET_NAME: office_home\n",
            "[CFG] DATA_ROOT: \n",
            "[CFG] TASK: Ar -> Cl\n",
            "[CFG] SEEDS: [0, 1, 2]\n",
            "[CFG] RUNS_ROOT: outputs/runs\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Dataset (single place to edit)\n",
        "DATASET_NAME = \"office_home\"  # office_home | office31\n",
        "DATA_ROOT = \"\"  # optional path; leave blank to auto-download\n",
        "\n",
        "# Optional: override via env vars (Colab-friendly)\n",
        "DATASET_NAME = os.getenv(\"DATASET_NAME\", DATASET_NAME)\n",
        "DATA_ROOT = os.getenv(\"DATA_ROOT\", DATA_ROOT)\n",
        "\n",
        "# Persist datasets + runs to Google Drive in Colab.\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "USE_DRIVE = IN_COLAB\n",
        "if USE_DRIVE:\n",
        "    DRIVE_ROOT = Path(\"/content/drive/MyDrive\")\n",
        "    if not DRIVE_ROOT.exists():\n",
        "        raise RuntimeError(\n",
        "            \"[Drive][ERROR] Expected /content/drive/MyDrive to exist. \"\n",
        "            \"Run the Drive mount cell first and confirm it prints '[Drive] OK'.\"\n",
        "        )\n",
        "    PERSIST_ROOT = DRIVE_ROOT / \"ME-IIS\"\n",
        "    PERSIST_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "    if not str(DATA_ROOT).strip():\n",
        "        if DATASET_NAME == \"office_home\":\n",
        "            DATA_ROOT = str(PERSIST_ROOT / \"datasets\" / \"Office-Home\")\n",
        "        elif DATASET_NAME == \"office31\":\n",
        "            DATA_ROOT = str(PERSIST_ROOT / \"datasets\" / \"Office-31\")\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown DATASET_NAME={DATASET_NAME}\")\n",
        "    RUNS_ROOT = PERSIST_ROOT / \"outputs\" / \"runs\"\n",
        "else:\n",
        "    RUNS_ROOT = Path(\"outputs\") / \"runs\"\n",
        "\n",
        "# Mode\n",
        "MODE = \"FULL\"  # QUICK | FULL\n",
        "FORCE_RERUN = False\n",
        "\n",
        "# Task\n",
        "SOURCE_DOMAIN = \"Ar\"  # Office-Home: Ar/Cl/Pr/Rw ; Office-31: A/D/W\n",
        "TARGET_DOMAIN = \"Cl\"\n",
        "\n",
        "# Seeds\n",
        "SEEDS = [0] if MODE == \"QUICK\" else [0, 1, 2]\n",
        "DETERMINISTIC = True\n",
        "\n",
        "# Training budget (fair across methods)\n",
        "EPOCHS_SOURCE = 2 if MODE == \"QUICK\" else 50\n",
        "EPOCHS_ADAPT = 2 if MODE == \"QUICK\" else 10\n",
        "BATCH_SIZE = 16 if MODE == \"QUICK\" else 32\n",
        "NUM_WORKERS = 2 if MODE == \"QUICK\" else 4\n",
        "\n",
        "# Optimizer schedule\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 1e-3\n",
        "LR_BACKBONE = 1e-3\n",
        "LR_CLASSIFIER = 1e-2\n",
        "\n",
        "# Adaptation optimizer schedule (shared)\n",
        "FINETUNE_BACKBONE = False\n",
        "BACKBONE_LR_SCALE = 0.1\n",
        "CLASSIFIER_LR_ADAPT = 1e-2\n",
        "\n",
        "# Optional speed limits (keep 0 for real runs)\n",
        "DRY_RUN_MAX_SAMPLES = 0\n",
        "DRY_RUN_MAX_BATCHES = 0\n",
        "\n",
        "# Where to store outputs.\n",
        "\n",
        "# ME-IIS params\n",
        "ME_IIS_PARAMS = {\n",
        "    \"feature_layers\": [\"layer3\", \"layer4\"],\n",
        "    \"num_latent_styles\": 5,\n",
        "    \"components_per_layer\": None,\n",
        "    \"cluster_backend\": \"gmm\",  # gmm | vmf_softmax\n",
        "    \"gmm_selection_mode\": \"bic\",  # fixed | bic\n",
        "    \"gmm_bic_min_components\": 2,\n",
        "    \"gmm_bic_max_components\": 8,\n",
        "    \"vmf_kappa\": 20.0,\n",
        "    \"cluster_clean_ratio\": 1.0,\n",
        "    \"kmeans_n_init\": 10,\n",
        "    \"source_prob_mode\": \"softmax\",  # softmax | onehot\n",
        "    \"iis_iters\": 5 if MODE == \"QUICK\" else 15,\n",
        "    \"iis_tol\": 1e-3,\n",
        "    \"use_pseudo_labels\": False,\n",
        "    \"pseudo_conf_thresh\": 0.9,\n",
        "    \"pseudo_max_ratio\": 1.0,\n",
        "    \"pseudo_loss_weight\": 1.0,\n",
        "}\n",
        "\n",
        "# DANN params\n",
        "DANN_PARAMS = {\n",
        "    \"disc_hidden_dim\": 1024,\n",
        "    \"disc_dropout\": 0.0,\n",
        "    \"dann_lambda_schedule\": \"grl\",  # grl | linear | constant\n",
        "    \"domain_loss_weight\": 1.0,\n",
        "}\n",
        "\n",
        "# CORAL params\n",
        "CORAL_PARAMS = {\n",
        "    \"feature_layers\": [\"layer3\", \"layer4\"],\n",
        "    \"coral_weight\": 1.0,\n",
        "}\n",
        "\n",
        "# Pseudo-label baseline params\n",
        "PL_PARAMS = {\n",
        "    \"pseudo_conf_thresh\": 0.9,\n",
        "    \"pseudo_max_ratio\": 1.0,\n",
        "    \"pseudo_loss_weight\": 1.0,\n",
        "}\n",
        "\n",
        "print(\"[CFG] MODE:\", MODE)\n",
        "print(\"[CFG] DATASET_NAME:\", DATASET_NAME)\n",
        "print(\"[CFG] DATA_ROOT:\", DATA_ROOT)\n",
        "print(\"[CFG] TASK:\", f\"{SOURCE_DOMAIN} -> {TARGET_DOMAIN}\")\n",
        "print(\"[CFG] SEEDS:\", SEEDS)\n",
        "print(\"[CFG] RUNS_ROOT:\", RUNS_ROOT)\n"
      ],
      "id": "esimj68EjCnJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAmlgumMjCnJ"
      },
      "source": [
        "## 3) Data (download/verify)\n",
        "\n",
        "Supports `office_home` and `office31`.\n",
        "- Leave `DATA_ROOT` blank to auto-download (KaggleHub).\n",
        "- If you already have the dataset (or in Drive), set `DATA_ROOT` in the config cell.\n"
      ],
      "id": "kAmlgumMjCnJ"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H318pyfTjCnK",
        "outputId": "579046a4-6da6-44c9-e64d-caacb4b195a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Data] DATA_ROOT not set; downloading via KaggleHub...\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/lhrrraname/officehome?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.06G/1.06G [00:54<00:00, 20.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Data] DATASET_NAME: office_home\n",
            "[Data] DATA_ROOT: /root/.cache/kagglehub/datasets/lhrrraname/officehome/versions/1/datasets/OfficeHomeDataset_10072016\n",
            "[Data] Exists: True\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def _find_office_home_root(base: Path) -> Path:\n",
        "    real_candidates = [\"RealWorld\", \"Real World\", \"Real_World\", \"Real\"]\n",
        "    candidates = [base] + [p for p in base.rglob(\"*\") if p.is_dir()]\n",
        "    for cand in candidates:\n",
        "        if all((cand / sub).exists() for sub in [\"Art\", \"Clipart\", \"Product\"]) and any((cand / r).exists() for r in real_candidates):\n",
        "            return cand\n",
        "    return base\n",
        "\n",
        "\n",
        "def _find_office31_root(base: Path) -> Path:\n",
        "    candidates = [base] + [p for p in base.rglob(\"*\") if p.is_dir()]\n",
        "    for cand in candidates:\n",
        "        names = {p.name.lower() for p in cand.iterdir() if p.is_dir()}\n",
        "        if {\"amazon\", \"dslr\", \"webcam\"} <= names:\n",
        "            return cand\n",
        "    return base\n",
        "\n",
        "\n",
        "def _download_via_kagglehub(dataset_name: str) -> Path:\n",
        "    try:\n",
        "        import kagglehub  # type: ignore\n",
        "    except ImportError:\n",
        "        import sys, subprocess\n",
        "\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"kagglehub\"], check=True)\n",
        "        import kagglehub  # type: ignore\n",
        "\n",
        "    if dataset_name == \"office_home\":\n",
        "        raw = Path(kagglehub.dataset_download(\"lhrrraname/officehome\"))\n",
        "        return _find_office_home_root(raw)\n",
        "    if dataset_name == \"office31\":\n",
        "        raw = Path(kagglehub.dataset_download(\"xixuhu/office31\"))\n",
        "        return _find_office31_root(raw)\n",
        "    raise ValueError(f\"Unknown DATASET_NAME={dataset_name}\")\n",
        "\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "drive_root = Path(\"/content/drive/MyDrive\")\n",
        "\n",
        "data_root_str = str(DATA_ROOT).strip()\n",
        "data_root_path = Path(data_root_str).expanduser() if data_root_str else None\n",
        "\n",
        "if data_root_path is None:\n",
        "    print(\"[Data] DATA_ROOT not set; downloading via KaggleHub...\")\n",
        "    data_root_path = _download_via_kagglehub(DATASET_NAME)\n",
        "else:\n",
        "    # If the user points DATA_ROOT to Drive but it's missing, download to runtime and copy to Drive.\n",
        "    is_drive_path = IN_COLAB and drive_root.exists() and str(data_root_path).replace(\"\\\\\", \"/\").startswith(\"/content/drive/\")\n",
        "    if is_drive_path and not data_root_path.exists():\n",
        "        print(f\"[Data] DATA_ROOT on Drive does not exist yet: {data_root_path}\")\n",
        "        print(\"[Data] Downloading via KaggleHub to runtime, then copying to Drive...\")\n",
        "        tmp_root = _download_via_kagglehub(DATASET_NAME)\n",
        "        data_root_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        shutil.copytree(tmp_root, data_root_path, dirs_exist_ok=True)\n",
        "\n",
        "    # Be forgiving if the user points to a parent directory.\n",
        "    if DATASET_NAME == \"office_home\":\n",
        "        expected = [\"Art\", \"Clipart\", \"Product\"]\n",
        "        if not all((data_root_path / sub).exists() for sub in expected):\n",
        "            data_root_path = _find_office_home_root(data_root_path)\n",
        "    elif DATASET_NAME == \"office31\":\n",
        "        expected = [\"amazon\", \"dslr\", \"webcam\"]\n",
        "        names = {p.name.lower() for p in data_root_path.iterdir() if p.is_dir()} if data_root_path.exists() else set()\n",
        "        if not set(expected) <= names:\n",
        "            data_root_path = _find_office31_root(data_root_path)\n",
        "\n",
        "DATA_ROOT = Path(data_root_path).resolve()\n",
        "print(\"[Data] DATASET_NAME:\", DATASET_NAME)\n",
        "print(\"[Data] DATA_ROOT:\", DATA_ROOT)\n",
        "print(\"[Data] Exists:\", DATA_ROOT.exists())\n"
      ],
      "id": "H318pyfTjCnK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHl9bvAKjCnK"
      },
      "source": [
        "## 4) Run source-only (skip/resume)\n"
      ],
      "id": "nHl9bvAKjCnK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0vBcD83jCnK",
        "outputId": "96f9e3d7-189a-4638-91e2-2e8667d04dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         method  seed  source_batches_per_epoch  target_batches_per_epoch  \\\n",
              "0   source_only     0                        76                       137   \n",
              "1        me_iis     0                        76                       137   \n",
              "2          dann     0                        76                       137   \n",
              "3         coral     0                        76                       137   \n",
              "4  pseudo_label     0                        76                       137   \n",
              "\n",
              "   steps_source  steps_adapt  steps_total  \n",
              "0          3800            0         3800  \n",
              "1          3800          760         4560  \n",
              "2          3800          760         4560  \n",
              "3          3800          760         4560  \n",
              "4          3800          760         4560  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11a90a0a-6140-4f74-b316-d8766affcbc7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>seed</th>\n",
              "      <th>source_batches_per_epoch</th>\n",
              "      <th>target_batches_per_epoch</th>\n",
              "      <th>steps_source</th>\n",
              "      <th>steps_adapt</th>\n",
              "      <th>steps_total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>source_only</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>137</td>\n",
              "      <td>3800</td>\n",
              "      <td>0</td>\n",
              "      <td>3800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>me_iis</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>137</td>\n",
              "      <td>3800</td>\n",
              "      <td>760</td>\n",
              "      <td>4560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dann</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>137</td>\n",
              "      <td>3800</td>\n",
              "      <td>760</td>\n",
              "      <td>4560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coral</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>137</td>\n",
              "      <td>3800</td>\n",
              "      <td>760</td>\n",
              "      <td>4560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pseudo_label</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>137</td>\n",
              "      <td>3800</td>\n",
              "      <td>760</td>\n",
              "      <td>4560</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11a90a0a-6140-4f74-b316-d8766affcbc7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11a90a0a-6140-4f74-b316-d8766affcbc7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11a90a0a-6140-4f74-b316-d8766affcbc7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a46f518a-d418-4c53-8b59-d129a5f8848e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a46f518a-d418-4c53-8b59-d129a5f8848e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a46f518a-d418-4c53-8b59-d129a5f8848e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    source_runs\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"me_iis\",\n          \"pseudo_label\",\n          \"dann\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_batches_per_epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 76,\n        \"max\": 76,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_batches_per_epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 137,\n        \"max\": 137,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          137\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"steps_source\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3800,\n        \"max\": 3800,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3800\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"steps_adapt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 339,\n        \"min\": 0,\n        \"max\": 760,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          760\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"steps_total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 339,\n        \"min\": 3800,\n        \"max\": 4560,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4560\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import inspect, traceback\n",
        "from src.experiments.run_config import RunConfig, get_run_dir\n",
        "from src.experiments.runner import run_one as _run_one\n",
        "\n",
        "def run_one_nb(cfg: RunConfig, **kwargs):\n",
        "    \"\"\"Notebook-safe wrapper around run_one (handles older runner.py versions).\"\"\"\n",
        "    try:\n",
        "        if 'raise_on_error' in inspect.signature(_run_one).parameters:\n",
        "            return _run_one(cfg, raise_on_error=False, **kwargs)\n",
        "        return _run_one(cfg, **kwargs)\n",
        "    except Exception as exc:\n",
        "        run_dir = get_run_dir(cfg, runs_root=kwargs.get('runs_root'))\n",
        "        try:\n",
        "            (run_dir / 'logs').mkdir(parents=True, exist_ok=True)\n",
        "            with (run_dir / 'logs' / 'stderr.txt').open('a', encoding='utf-8') as f:\n",
        "                f.write('\\\\n' + traceback.format_exc() + '\\\\n')\n",
        "        except Exception:\n",
        "            pass\n",
        "        return {\n",
        "            'status': 'failed',\n",
        "            'run_dir': str(run_dir),\n",
        "            'checkpoint': None,\n",
        "            'metrics_csv': None,\n",
        "            'error': f\"{type(exc).__name__}: {exc}\",\n",
        "        }\n",
        "\n",
        "def make_cfg(method: str, seed: int, method_params: dict | None = None) -> RunConfig:\n",
        "    return RunConfig(\n",
        "        dataset_name=DATASET_NAME,\n",
        "        data_root=str(DATA_ROOT),\n",
        "        source_domain=SOURCE_DOMAIN,\n",
        "        target_domain=TARGET_DOMAIN,\n",
        "        method=method,\n",
        "        epochs_source=EPOCHS_SOURCE,\n",
        "        epochs_adapt=0 if method == \"source_only\" else EPOCHS_ADAPT,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=NUM_WORKERS,\n",
        "        momentum=MOMENTUM,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        lr_backbone=LR_BACKBONE,\n",
        "        lr_classifier=LR_CLASSIFIER,\n",
        "        finetune_backbone=False if method == \"source_only\" else FINETUNE_BACKBONE,\n",
        "        backbone_lr_scale=0.1 if method == \"source_only\" else BACKBONE_LR_SCALE,\n",
        "        classifier_lr=1e-2 if method == \"source_only\" else CLASSIFIER_LR_ADAPT,\n",
        "        seed=seed,\n",
        "        deterministic=DETERMINISTIC,\n",
        "        dry_run_max_samples=DRY_RUN_MAX_SAMPLES,\n",
        "        dry_run_max_batches=DRY_RUN_MAX_BATCHES,\n",
        "        method_params={} if method == \"source_only\" else (method_params or {}),\n",
        "    )\n",
        "\n",
        "# Fairness guard: approximate optimizer-step budgets (epochs × batches)\n",
        "from src.experiments.budget import estimate_total_steps\n",
        "import pandas as pd\n",
        "\n",
        "budget_seed = SEEDS[0]\n",
        "budget_rows = []\n",
        "for method, params in [\n",
        "    (\"source_only\", {}),\n",
        "    (\"me_iis\", ME_IIS_PARAMS),\n",
        "    (\"dann\", DANN_PARAMS),\n",
        "    (\"coral\", CORAL_PARAMS),\n",
        "    (\"pseudo_label\", PL_PARAMS),\n",
        "]:\n",
        "    cfg_b = make_cfg(method, budget_seed, method_params=params)\n",
        "    budget_rows.append({\"method\": method, \"seed\": budget_seed, **estimate_total_steps(cfg_b)})\n",
        "display(pd.DataFrame(budget_rows))\n",
        "\n",
        "source_runs = []\n",
        "for seed in SEEDS:\n",
        "    cfg = make_cfg(\"source_only\", seed)\n",
        "    res = run_one_nb(cfg, force_rerun=FORCE_RERUN, runs_root=RUNS_ROOT)\n",
        "    print(f\"[source_only][seed={seed}] status={res['status']} src_acc={res.get('source_acc_eval')} tgt_acc={res.get('target_acc_eval')} run_dir={res['run_dir']} ckpt={res.get('checkpoint')} metrics={res.get('metrics_csv')} error={res.get('error')}\")\n",
        "    source_runs.append(res)\n"
      ],
      "id": "_0vBcD83jCnK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkjdtg0MjCnL"
      },
      "source": [
        "## 5) Run adaptation (ME-IIS)\n"
      ],
      "id": "qkjdtg0MjCnL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5VUqe1qjCnL"
      },
      "outputs": [],
      "source": [
        "me_iis_runs = []\n",
        "for seed in SEEDS:\n",
        "    cfg = make_cfg(\"me_iis\", seed, method_params=ME_IIS_PARAMS)\n",
        "    res = run_one_nb(cfg, force_rerun=FORCE_RERUN, runs_root=RUNS_ROOT)\n",
        "    print(f\"[me_iis][seed={seed}] status={res['status']} src_acc={res.get('source_acc_eval')} tgt_acc={res.get('target_acc_eval')} run_dir={res['run_dir']} ckpt={res.get('checkpoint')} metrics={res.get('metrics_csv')} error={res.get('error')}\")\n",
        "    me_iis_runs.append(res)\n"
      ],
      "id": "a5VUqe1qjCnL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C81MO5wrjCnL"
      },
      "source": [
        "## 6) Run baselines (DANN / CORAL / pseudo-label)\n"
      ],
      "id": "C81MO5wrjCnL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRdJek-NjCnL"
      },
      "outputs": [],
      "source": [
        "baseline_runs = []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    cfg = make_cfg(\"dann\", seed, method_params=DANN_PARAMS)\n",
        "    res = run_one_nb(cfg, force_rerun=FORCE_RERUN, runs_root=RUNS_ROOT)\n",
        "    print(f\"[dann][seed={seed}] status={res['status']} src_acc={res.get('source_acc_eval')} tgt_acc={res.get('target_acc_eval')} run_dir={res['run_dir']} ckpt={res.get('checkpoint')} metrics={res.get('metrics_csv')} error={res.get('error')}\")\n",
        "    baseline_runs.append(res)\n",
        "\n",
        "for seed in SEEDS:\n",
        "    cfg = make_cfg(\"coral\", seed, method_params=CORAL_PARAMS)\n",
        "    res = run_one_nb(cfg, force_rerun=FORCE_RERUN, runs_root=RUNS_ROOT)\n",
        "    print(f\"[coral][seed={seed}] status={res['status']} src_acc={res.get('source_acc_eval')} tgt_acc={res.get('target_acc_eval')} run_dir={res['run_dir']} ckpt={res.get('checkpoint')} metrics={res.get('metrics_csv')} error={res.get('error')}\")\n",
        "    baseline_runs.append(res)\n",
        "\n",
        "for seed in SEEDS:\n",
        "    cfg = make_cfg(\"pseudo_label\", seed, method_params=PL_PARAMS)\n",
        "    res = run_one_nb(cfg, force_rerun=FORCE_RERUN, runs_root=RUNS_ROOT)\n",
        "    print(f\"[pseudo_label][seed={seed}] status={res['status']} src_acc={res.get('source_acc_eval')} tgt_acc={res.get('target_acc_eval')} run_dir={res['run_dir']} ckpt={res.get('checkpoint')} metrics={res.get('metrics_csv')} error={res.get('error')}\")\n",
        "    baseline_runs.append(res)\n",
        "\n",
        "print(\"[Logs] Each run writes logs to: <run_dir>/logs/stdout.txt and <run_dir>/logs/stderr.txt\")\n"
      ],
      "id": "iRdJek-NjCnL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHBcl650jCnM"
      },
      "source": [
        "## 7) Summaries (tables + plots)\n"
      ],
      "id": "aHBcl650jCnM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQpCyZy1jCnM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.experiments.notebook_summary import collect_expected_runs\n",
        "\n",
        "expected_cfgs = []\n",
        "for seed in SEEDS:\n",
        "    expected_cfgs.append(make_cfg(\"source_only\", seed))\n",
        "    expected_cfgs.append(make_cfg(\"me_iis\", seed, method_params=ME_IIS_PARAMS))\n",
        "    expected_cfgs.append(make_cfg(\"dann\", seed, method_params=DANN_PARAMS))\n",
        "    expected_cfgs.append(make_cfg(\"coral\", seed, method_params=CORAL_PARAMS))\n",
        "    expected_cfgs.append(make_cfg(\"pseudo_label\", seed, method_params=PL_PARAMS))\n",
        "\n",
        "rows = collect_expected_runs(expected_cfgs, runs_root=RUNS_ROOT)\n",
        "df = pd.DataFrame(rows)\n",
        "df[\"target_acc_num\"] = pd.to_numeric(df.get(\"target_acc\"), errors=\"coerce\")\n",
        "df[\"target_display\"] = df.apply(lambda r: r[\"target_acc_num\"] if r[\"status\"] == \"OK\" else r[\"status\"], axis=1)\n",
        "\n",
        "print(f\"[Summary] Expected runs: {len(expected_cfgs)}\")\n",
        "display(df[[\"method\", \"seed\", \"status\", \"source_acc\", \"target_acc\", \"run_id\", \"metrics_csv\"]])\n",
        "\n",
        "pivot = df.pivot(index=\"method\", columns=\"seed\", values=\"target_display\").fillna(\"NOT RUN\")\n",
        "print(\"Target accuracy by method x seed (or status):\")\n",
        "display(pivot)\n",
        "\n",
        "ok = df[df[\"status\"] == \"OK\"].copy()\n",
        "if ok.empty:\n",
        "    print(\"No successful runs yet.\")\n",
        "else:\n",
        "    stats = ok.groupby(\"method\")[\"target_acc_num\"].agg([\"mean\", \"std\", \"count\"]).reset_index()\n",
        "    stats = stats.sort_values(\"mean\", ascending=False)\n",
        "    stats[\"std\"] = stats[\"std\"].fillna(0.0)\n",
        "    print(\"Mean ± std (target_acc over OK runs):\")\n",
        "    display(stats)\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar(stats[\"method\"], stats[\"mean\"], yerr=stats[\"std\"], capsize=4)\n",
        "    plt.ylabel(\"Target Acc (%)\")\n",
        "    plt.title(f\"{DATASET_NAME} {SOURCE_DOMAIN}→{TARGET_DOMAIN} (mean±std over seeds)\")\n",
        "    plt.xticks(rotation=30, ha=\"right\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "id": "VQpCyZy1jCnM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jsjms0AjCnM"
      },
      "source": [
        "## 8) Export artifacts\n"
      ],
      "id": "5Jsjms0AjCnM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhTDNPh8jCnM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from utils.experiment_utils import dataset_tag\n",
        "from src.experiments.notebook_summary import collect_expected_runs\n",
        "\n",
        "expected_cfgs = []\n",
        "for seed in SEEDS:\n",
        "    expected_cfgs.append(make_cfg(\"source_only\", seed))\n",
        "    expected_cfgs.append(make_cfg(\"me_iis\", seed, method_params=ME_IIS_PARAMS))\n",
        "    expected_cfgs.append(make_cfg(\"dann\", seed, method_params=DANN_PARAMS))\n",
        "    expected_cfgs.append(make_cfg(\"coral\", seed, method_params=CORAL_PARAMS))\n",
        "    expected_cfgs.append(make_cfg(\"pseudo_label\", seed, method_params=PL_PARAMS))\n",
        "\n",
        "rows = collect_expected_runs(expected_cfgs, runs_root=RUNS_ROOT)\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "ds_tag = dataset_tag(DATASET_NAME)\n",
        "pair = f\"{SOURCE_DOMAIN}2{TARGET_DOMAIN}\"\n",
        "out_dir = RUNS_ROOT / ds_tag / pair\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "export_path = out_dir / \"all_metrics.csv\"\n",
        "df.to_csv(export_path, index=False)\n",
        "print(\"[Export] Wrote:\", export_path)\n"
      ],
      "id": "rhTDNPh8jCnM"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
