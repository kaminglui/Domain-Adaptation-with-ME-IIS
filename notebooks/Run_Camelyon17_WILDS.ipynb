{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run Camelyon17 (WILDS)\n",
        "\n",
        "This notebook is a thin orchestrator for running ERM, DANN, and ME-IIS on Camelyon17 using the official `wilds` loader + `dataset.eval(...)`.\n",
        "\n",
        "It is designed to be re-runnable: existing datasets/checkpoints are reused, and training is skipped unless `FORCE_RERUN=True`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Drive mount + paths\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "# Outputs/checkpoints (Drive by default in Colab).\n",
        "DRIVE_ROOT = os.environ.get(\n",
        "    \"MEIIS_DRIVE_ROOT\",\n",
        "    \"/content/drive/MyDrive/ME-IIS\" if IN_COLAB else os.getcwd(),\n",
        ")\n",
        "\n",
        "# Dataset cache root:\n",
        "# - Drive: persistent across runtimes (no re-download), but slower I/O.\n",
        "# - Local scratch: faster, but wiped when runtime resets.\n",
        "USE_DRIVE_WILDS_CACHE = True if IN_COLAB else False\n",
        "DATA_ROOT_DEFAULT = (\n",
        "    os.path.join(DRIVE_ROOT, \"data\", \"wilds\")\n",
        "    if (IN_COLAB and USE_DRIVE_WILDS_CACHE)\n",
        "    else (\"/content/data/wilds\" if IN_COLAB else os.path.join(os.getcwd(), \"datasets\", \"wilds\"))\n",
        ")\n",
        "DATA_ROOT = os.environ.get(\"WILDS_DATA_ROOT\", DATA_ROOT_DEFAULT)\n",
        "os.environ[\"WILDS_DATA_ROOT\"] = DATA_ROOT\n",
        "CKPT_ROOT = os.path.join(DRIVE_ROOT, \"checkpoints_camelyon17\")\n",
        "OUT_ROOT = os.path.join(DRIVE_ROOT, \"outputs_camelyon17\")\n",
        "\n",
        "print(\"DATA_ROOT:\", DATA_ROOT)\n",
        "print(\"CKPT_ROOT:\", CKPT_ROOT)\n",
        "print(\"OUT_ROOT:\", OUT_ROOT)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Repo + commit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, subprocess\n",
        "\n",
        "if os.path.isdir(\".git\"):\n",
        "    commit = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]).decode().strip()\n",
        "    print(\"commit:\", commit)\n",
        "else:\n",
        "    print(\"NOTE: current working directory is not a git repo; skipping commit print.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Install deps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip -q install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Configure experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FORCE_RERUN = False\n",
        "SEEDS = [0]\n",
        "\n",
        "# Protocol:\n",
        "# - \"uda_target\": adapt on test_unlabeled (target unlabeled), select on val, report on test.\n",
        "# - \"align_val\": adapt on val_unlabeled, evaluate on val (debug/ablation only).\n",
        "SPLIT_MODE = \"uda_target\"  # uda_target | align_val\n",
        "\n",
        "# Fair default compute budget (keep identical across methods unless intentionally changed).\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 64\n",
        "BACKBONE = \"densenet121\"  # densenet121 | resnet50\n",
        "PRETRAINED = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Run ERM + DANN + ME-IIS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import replace\n",
        "\n",
        "from src.run_experiments import default_camelyon17_configs, run_experiments\n",
        "\n",
        "configs = []\n",
        "for seed in SEEDS:\n",
        "    for cfg in default_camelyon17_configs(seed=seed, split_mode=SPLIT_MODE, force_rerun=FORCE_RERUN):\n",
        "        cfg = replace(cfg, epochs=EPOCHS, batch_size=BATCH_SIZE, backbone=BACKBONE, pretrained=PRETRAINED)\n",
        "        configs.append(cfg)\n",
        "\n",
        "summary_path = run_experiments(\n",
        "    configs,\n",
        "    data_root=DATA_ROOT,\n",
        "    ckpt_root=CKPT_ROOT,\n",
        "    out_root=OUT_ROOT,\n",
        ")\n",
        "print(\"summary_path:\", summary_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Aggregate metrics + plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(summary_path)\n",
        "display(df)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 3))\n",
        "ax.bar(df[\"algorithm\"].astype(str), df[\"eval_acc\"].astype(float))\n",
        "ax.set_title(\"Camelyon17 (WILDS)\")\n",
        "ax.set_ylabel(\"Eval accuracy\")\n",
        "ax.grid(True, axis=\"y\", alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Save outputs to Drive\n",
        "\n",
        "All artifacts are already written under `OUT_ROOT` and `CKPT_ROOT` (defaults to Drive in Colab)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
